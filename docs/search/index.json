[{"content":"この記事のテーマ 一ヶ月前に書いた前回の記事ではプロンプティングについて調べました。その延長として極端にプロンプティングを極めるとどうなるか、という例もいくつか収集したのにアップするのを忘れていました。その他、ChatGPTに関わるハイレベルな内容もまとめます。\n一ヶ月の間に色々と状況が変わった部分もあるので、適宜補足も加えます。\nプロンプティングスキルを極めた例 無数のペルソナを生み出して、ペルソナ同士で考えさせる まじやばい！やった人はスクショ希望！\n目標：献立を考える\n専門家の数： 100…\n\u0026mdash; Shunsuke Hayashi（林 駿甫） (@HaveShun) March 23, 2023 ShunsukeさんはLLM(大規模言語モデル, ChatGPTやBardを支えるAI技術)の専門家ではないそうですが、経験的な観点から素晴らしい洞察をChatGPTに与えておられます。\nNewsPicksで落合陽一さんがChatGPTについて語ってらっしゃいましたが、Twitter上で落合さんがShunsukeさんのことべた褒めしてましたね。Shunsukeさんや落合さんらが[変数]などと特定の概念を抽象化するようなプロンプトデザインのやりかたをX-promptと呼ぶそうです。\nShunsukeさんのめちゃめちゃ長いプロンプトを実行すると、次のようなものができます。\nクリックでプロンプト全文をみる 目標：献立を考える\n専門家の数： 100 専門家の数に対して専門家のペルソナを設定して専門家を具体的に表現してから専門家を使用してください専門家の表現の仕方は何の専門家であるかを明確に書いてください勝つ名前バックグラウンド覆面全て検討して考えて書いてください\nプロンプト1:\n抽象オブジェクト：[抽象オブジェクトを記述]\nサブオブジェクト：[サブオブジェクト1]、[サブオブジェクト2]、[サブオブジェクト3]\u0026hellip;\n知識：[知識1]、[知識2]、[知識3]\u0026hellip;\n能力：[能力1]、[能力2]、[能力3]\u0026hellip;\n管理オブジェクト：[管理オブジェクト1]、[管理オブジェクト2]、[管理オブジェクト3]\u0026hellip;\nプロンプト2:\n[手順1] [手順2] [手順3] \u0026hellip; N. [手順N] 専門家プロンプト：\n[専門家1のプロンプト1] [専門家1のプロンプト2] \u0026hellip; N. [専門家1のプロンプトN] [各専門家に対して上記のプロンプトを提供し、回答を収集します。]\nプロンプトの評価：\n評価基準アウトカム1のスコアアウトカム2のスコア専門家プロンプトのスコア 明確さ[スコア1][スコア2][専門家プロンプト1のスコア] 実行可能性[スコア1][スコア2][専門家プロンプト2のスコア] 網羅性[スコア1][スコア2][専門家プロンプト3のスコア] 柔軟性[スコア1][スコア2][専門家プロンプト4のスコア] 目標達成の確率[スコア1][スコア2][専門家プロンプト5のスコア] 合計スコア[合計スコア1][合計スコア2][合計専門家プロンプトスコア] 最終アウトカムの選択とプロセス：\n最終的なプロセスは、プロンプト1とプロンプト2のスコアの合計が最も高いものを選択します。また、専門家プロンプトのスコアも考慮に入れ、最終的な決定を下します。ただし、専門家プロンプトのスコアは、プロンプト1とプロンプト2のスコアよりも重要度が低いことに注意してください。\n具体的には、以下の手順を実行します：\nプロンプト1とプロンプト2を使用して、複数の回答を収集します。 各回答のスコアを評価基準に基づいて計算します。 各回答の合計スコアを計算します。 最も高い合計スコアを持つ回答を選択します。 専門家プロンプトのスコアを考慮に入れ、最終的な決定を下します。 このプロセスを踏まえて、目標を達成するために必要なアクションプランを策定することができます。また、このプロセスは、複数の専門家の知識や能力を結集し、より正確な結論を導き出すことができます。\nクリックで全文をみる 目標：献立を考える\n抽象オブジェクト：献立\nサブオブジェクト：前菜、主菜、デザート\n知識：栄養バランス、旬の食材、調理方法\n能力：料理の組み合わせ、味のバランス、食材選び\n管理オブジェクト：栄養価、食材コスト、調理時間\n以下は、5名の専門家のペルソナ例です。\n専門家1：山田太郎\n背景：フレンチ料理のシェフ 知識：フランス料理、旬の食材、ワイン 能力：フレンチ料理の組み合わせ、味のバランス、食材選び 専門家2：佐藤花子\n背景：管理栄養士 知識：栄養学、食材の栄養価、食事バランス 能力：栄養バランスの良い献立作り、食材選び 専門家3：鈴木一郎\n背景：イタリア料理のシェフ 知識：イタリア料理、パスタ、チーズ 能力：イタリア料理の組み合わせ、味のバランス、食材選び 専門家4：田中美咲\n背景：和食料理人 知識：和食、旬の食材、日本の食文化 能力：和食の組み合わせ、味のバランス、食材選び 専門家5：高橋健太\n背景：料理研究家 知識：家庭料理、レシピ開発、食材の保存方法 能力：簡単で美味しい料理の提案、レシピ開発 手順1：各専門家に献立案を提案してもらう 手順2：提案された献立を栄養バランス、食材コスト、調理時間の観点から評価する 手順3：評価結果を基に最適な献立を選ぶ\n専門家プロンプト：\n専門家1のプロンプト1：フレンチ料理をベースにした献立案を提案してください。 専門家1のプロンプト2：旬の食材を活かしたフレンチ料理の組み合わせを教えてください。\n専門家2のプロンプト1：栄養バランスが良い献立案を提案してください。 専門家2のプロンプト2：食材選びのポイントを説明してください。\n専門家3のプロンプト1：イタリア料理をベースにした献立案を提案してください。 専門家3のプロンプト2：パスタとチーズを活かした料理の組み合わせを教えてください。\n専門家4のプロンプト1：和食をベースにした献立案を提案してください。 専門家4のプロンプト2：旬の食材を活かした和食の組み合わせを教えてください。\n専門家5のプロンプト1：家庭料理をベースにした献立案を提案してください。 専門家5のプロンプト2：手軽で美味しい料理の提案を教えてください。\n各専門家からの回答を収集した後、評価基準に従ってスコアを付け、最適な献立を選択します。最終的な決定は、専門家プロンプトのスコアも考慮に入れますが、プロンプト1とプロンプト2のスコアが優先されます。\n各専門家からの献立案を収集する 評価基準（明確さ、実行可能性、網羅性、柔軟性、目標達成の確率）に基づいて、各献立案にスコアを付ける 各献立案の合計スコアを計算する 最も高い合計スコアを持つ献立案を選択する 専門家プロンプトのスコアを考慮に入れ、最終的な決定を下す このプロセスを踏まえて、目標である献立を考えるためのアクションプランを策定することができます。また、このプロセスは、複数の専門家の知識や能力を結集し、より正確な結論を導き出すことができます。\nまだ返答は完成していません。今行われたのは「ゴールを達成するプロセスを理解させ、第一段階として架空の料理人を生み出しただけ」です。\n次に、そのプロセスに従って献立を考えてください。(=ゴールを達成せよ)と命じてみます。\nクリックで全文をみる 専門家1（フレンチ料理）： 前菜：季節の野菜のサラダ、ビネグレットソース 主菜：骨付き鶏もも肉のコンフィ、ロースト野菜添え デザート：アップルタルト、バニラアイスクリーム\n専門家2（管理栄養士）： 前菜：ミックスビーンズサラダ、ヨーグルトドレッシング 主菜：焼き魚、玄米ご飯、ほうれん草のごま和え デザート：カットフルーツ\n専門家3（イタリア料理）： 前菜：カプレーゼサラダ 主菜：ペンネアラビアータ、ガーリックパン デザート：ティラミス\n専門家4（和食料理人）： 前菜：季節のお浸し、刺身盛り合わせ 主菜：煮魚、ごはん、味噌汁 デザート：抹茶アイスクリーム\n専門家5（料理研究家）： 前菜：コールスローサラダ 主菜：チキンカレー、ご飯 デザート：プリン\n評価基準に基づいてスコアをつけた結果は以下の通りです。\n専門家1（フレンチ料理）： 明確さ：5 実行可能性：3 網羅性：4 柔軟性：3 目標達成の確率：4 合計スコア：19\n専門家2（管理栄養士）： 明確さ：4 実行可能性：5 網羅性：5 柔軟性：4 目標達成の確率：5 合計スコア：23\n専門家3（イタリア料理）： 明確さ：4 実行可能性：4 網羅性：3 柔軟性：3 目標達成の確率：4 合計スコア：18\n専門家4（和食料理人）： 明確さ：4 実行可能性：4 網羅性：4 柔軟性：4 目標達成の確率：4 合計スコア：20\n専門家5（料理研究家）： 明確さ：5 実行可能性：5 網羅性：3 柔軟性：柔軟性：3 目標達成の確率：4 合計スコア：20\n評価基準に基づくと、専門家2（管理栄養士）の献立案が最も高い合計スコア（23）を持っています。したがって、この献立案が最も適切な選択となります。\n最終的な献立：\n前菜：ミックスビーンズサラダ、ヨーグルトドレッシング 主菜：焼き魚、玄米ご飯、ほうれん草のごま和え デザート：カットフルーツ\nこのプロセスにより、目標である献立を考えるためのアクションプランが策定されました。各専門家の知識や能力を結集し、より正確な結論を導き出すことができました。\nこのプロンプトの何がすごいかというと、「今日の献立を考えて」といった抽象的なゴールを達成するために何を考慮すべきなのかを我々が知らなくても、思考のプロセスを与えるだけでChatGPTが考えてくれるという点です。\nShunsukeさんはこれ以外にもゴールシークプロンプトというものを開発されています。ゴールシークプロンプトでは、ゴールを抽象的なものであると定義し、ゴールを達成するために必要なプロセスも曖昧なものであると定義します。その上で、ゴールを達成するために必要なプロセスを一からChatGPTに考えさせることで、step-by-stepで理論を組み立て、最終的にゴールを達成します。\n例えば、ただ「ブログを書いて」とか「本を書いて」という命令は明らかにいい加減なプロンプティングですが、このゴールシークプロンプトを使うと、ChatGPTはプロセスごと何かを創作し提案してくれます。実際にこうして生成されたブログや本が有益かどうかはさておき、ゴールシークプロンプトは自分が対処できない課題に対してどういうアプローチを取るべきなのかを教わるにはこの上なく良いアプローチになるだろうと思っています。\nそんなにこのメソッドが凄いならサービス化すればいいじゃないか、と思っていましたが、数週間前にサービス化されています。GoalGPT: https://beta.nando.ai/goalgpt.php あなたはプロの**です これは有名な方法ですが、「あなたはプロの何々です」と言ってから本題の命令を与えると格段に精度が上がることがあります。\nたとえば、私はPythonコードをChatGPTに教えて貰うことがあるのですが、普通は以下のようにプロンプトを投げるでしょう。\npythonで以下を実装してください。\n一秒ごとに数字をカウントアップ カウントアップする数字はFuzzBizz問題を適用 GUIで数字とFuzzBizzを美しいUIで表示 結果は以下です。\nクリックして結果をみる Pythonでは、Tkinterを使ってGUIを作成し、FuzzBizz問題の実装と一秒ごとのカウントアップを行うことができます。以下はその実装例です。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 python Copy code import tkinter as tk import time def fuzz_bizz(n): if n % 3 == 0 and n % 5 == 0: return \u0026#34;FuzzBizz\u0026#34; elif n % 3 == 0: return \u0026#34;Fuzz\u0026#34; elif n % 5 == 0: return \u0026#34;Bizz\u0026#34; else: return str(n) def update_counter(): global counter counter += 1 label_counter.config(text=f\u0026#34;カウントアップ: {counter}\u0026#34;) label_fuzz_bizz.config(text=f\u0026#34;FuzzBizz: {fuzz_bizz(counter)}\u0026#34;) root.after(1000, update_counter) counter = 0 root = tk.Tk() root.title(\u0026#34;FuzzBizz カウンター\u0026#34;) label_counter = tk.Label(root, text=f\u0026#34;カウントアップ: {counter}\u0026#34;, font=(\u0026#34;Helvetica\u0026#34;, 16)) label_counter.pack(pady=10) label_fuzz_bizz = tk.Label(root, text=f\u0026#34;FuzzBizz: {fuzz_bizz(counter)}\u0026#34;, font=(\u0026#34;Helvetica\u0026#34;, 16)) label_fuzz_bizz.pack(pady=10) update_counter() root.mainloop() このコードをPythonファイルに保存して実行すると、一秒ごとにカウントアップし、FuzzBizz問題を適用した結果が表示されるGUIが表示されます。カウントアップはupdate_counter関数で行い、一秒ごとにこの関数が実行されるように設定しています。FuzzBizz問題はfuzz_bizz関数で実装しています。\nまあまあ、最低限うまく実装したなという感じがします。さすがと言うべきか、コードを一切編集せずに実行可能です。\nでは次に、ロールを与えてから同じ問題を与えてみましょう。 ポイントは、説明の仕方やコードの質についての指示\nあなたはSenior Python programmerで、WebデザインやUI/UXにも精通しています。あなたの仕事は与えられた命題をPythonや他の言語も利用しながら効率よくスマートに実装することであり、あなたの作成するcodeにはメンテナンスのしやすさや維持のしやすさが重視されている必要があります。そのため、ラインコメントを適宜使用し、後任の人物にもわかりやすいようなコード作成をする必要があります。\n以下をpythonで実装し、それを若手の新入社員に説明してください。\n一秒ごとに数字をカウントアップ カウントアップする数字はFuzzBizz問題を適用 GUIで数字とFuzzBizzを美しいUIで表示 クリックして開く まず、PythonでFuzzBizz問題を解決し、一秒ごとに数字をカウントアップするプログラムを作成します。次に、Tkinterを使用してGUIを作成し、カウントアップとFuzzBizzの結果を美しいUIで表示します。以下にコードを示します。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 import time from tkinter import * from tkinter import ttk def fizz_buzz(number): \u0026#34;\u0026#34;\u0026#34;FuzzBizz問題を解決する関数です。 引数: number (int): FuzzBizz問題に適用する整数 戻り値: str: FuzzBizz問題の結果 \u0026#34;\u0026#34;\u0026#34; if number % 15 == 0: return \u0026#34;FizzBuzz\u0026#34; elif number % 3 == 0: return \u0026#34;Fizz\u0026#34; elif number % 5 == 0: return \u0026#34;Buzz\u0026#34; else: return str(number) def update_count(): \u0026#34;\u0026#34;\u0026#34;カウントアップする数字とFuzzBizzの結果を更新し、ラベルに表示します。\u0026#34;\u0026#34;\u0026#34; global count count += 1 count_label.config(text=str(count)) fizz_buzz_result = fizz_buzz(count) fizz_buzz_label.config(text=fizz_buzz_result) root.after(1000, update_count) count = 0 # GUIの作成 root = Tk() root.title(\u0026#34;FizzBuzzカウンター\u0026#34;) frame = ttk.Frame(root, padding=\u0026#34;30 15\u0026#34;) frame.grid(row=0, column=0, sticky=(W, E, N, S)) count_label = ttk.Label(frame, text=str(count), font=(\u0026#34;Helvetica\u0026#34;, 24)) count_label.grid(row=0, column=0, pady=10) fizz_buzz_label = ttk.Label(frame, text=\u0026#34;\u0026#34;, font=(\u0026#34;Helvetica\u0026#34;, 24)) fizz_buzz_label.grid(row=1, column=0, pady=10) # カウントアップとFuzzBizzの結果を更新 root.after(1000, update_count) root.mainloop() このコードを新入社員に説明します。\nまず、fizz_buzz関数はFuzzBizz問題を解決するために作成されました。引数として整数を受け取り、FizzBuzzのルールに従って結果を返します。 update_count関数は、カウントアップの数字を更新し、FuzzBizzの結果を計算してGUI上に表示するために使用されます。 Tkinterを使用して、メインウィンドウとラベルを作成しています。frameはレイアウトを整えるために使用されています。 root.after(1000, update_count)を使って、1秒ごとにupdate_count関数が実行されるようにしています。これにより、カウントアップが実現されます。 最後にroot.mainloop()でGUIが表示され、プログラムが実行されます。 このコードを実行すると、数字が1秒ごとにカウントアップされ、FuzzBBuzzの結果が\u0026gt;GUI上に表示されます。このプログラムは、簡潔かつ効率的にFizzBuzz問題とカウントアップの結果を扱っています。また、コメントを適宜使用してコードの可読性を向上させています。これにより、後任の人物がコードを理解しやすくなります。\n新入社員に以下の点を強調して説明します。\u0026gt;\n関数の役割とパラメータ: fizz_buzzとupdate_count関数は、それぞれ何をするために\u0026gt;存在し、どのような引数を受け取るのかを理解することが重要です。また、各関数がどのような値を返すかも説明しておきます。\nグローバル変数の使用: このプログラムでは、countをグローバル変数として使用しています。countはカウントアップの数字を保持し、関数内で更新されます。グローバル変数は適切に使用することで、プログラムの状態を管理しやすくなりますが、過度な使用は避けるべきです。\nTkinterの基本: Tkinterは、Pythonの標準ライブラリでGUIアプリケーションを作成するためのものです。ウィジェット（ラベルやボタンなど）の作成と配置、イベントの管理など、Tkinterを使用する際の基本的な概念を説明します。\nイベント駆動プログラミング: root.after(1000, update_count)は、イベント駆動プロ\u0026gt;グラミングの一例です。このコードにより、1000ミリ秒（1秒）ごとにupdate_count関数が呼び出されます。イベント駆動プログラミングは、特定のイベント（時間経過、ボタンクリックなど）が発生したときに関数を実行する方法で、GUIアプリケーションにおいて一般的に使用されます。\n以上の説明を行い、新入社員がコードの構造と仕組みを理解できるようにサポートします。また、質問があれば適宜対応し、理解を深めることができるように助けます。\n今回は劇的にコードの質が上がったわけではないですが、思った通りにdocstringsなどを書き加えてくれました。何度か試すと分かるのですが、ChatGPTは必ずしも思ったとおりの実装をしてくれるわけではありません。これがロール付与で解決するケースが多い気がするという感じ。\nちなみに、Awesome ChatGPT PromptsではLinuxターミナルやJapanese Kanji quiz machineなどの変なロールを与える例についても紹介されています。\nChatGPTで気をつけたい話題 嘘つき 有名な話ですが、ChatGPTは事実では無いことやChatGPTが知らない事に関して、知ったかぶりをします。この現象はhallucinationと言われています。ChatGPT3.5ではそれが露骨だったのですが、GPT4ではかなりの部分で改善しているそうです。\nChatGPTには極めて深刻な問題、Hallucinationを抱えています。Hallucinationは噛み砕いていうと、しれっと嘘をつく現象です。ユーザーがこの嘘を嘘と見抜けない領域にChatGPTを適用するのは誤った理解を促す可能性があります。これはインターネット黎明期に似ています。https://t.co/3hQmbyVpRw\n\u0026mdash; あるふ (@alfredplpl) March 26, 2023 また、現在クローズドベータテスト中の機能でWebGPTという検索機能を含むChatGPTもあるそうです。GPT4を搭載しかつ検索にもチューニングされたモデルとしてはBing検索も質が高いですね。検索情報を引用しつつ回答を作成してくれるAIなら多少信用度が増します。\n以前からあるものとしてはperplexity.aiも非常に良いです。\nこれらのように検索エンジンを使い、出典を明記してくれるなら信用度は格段に上がります。\nとは言えネットの情報がデマである可能性を忘れてはなりません。いくら出典が添付されていても真実は自分で読んで確かめるのが一番です。 勢力争い GoogleのBardだけではなく、様々なAIが登場してきています。とりわけChatGPTを開発しているOpenAIはマイクロソフトの資金提供を受けていますから、マイクロソフト社の製品に次々とChatGPTが組み込まれています。BaiduやGoogleなどの他の営利企業は、この情況を良く思っておらず非常に焦っている姿が伺えます。\nOpenAIの共同創業者でもあったイーロンマスクは、最早OpenAIが非営利企業ではなく、営利企業のマイクロソフトのための犬になってしまっていると批判しています。\nOpenAI was created as an open source (which is why I named it “Open” AI), non-profit company to serve as a counterweight to Google, but now it has become a closed source, maximum-profit company effectively controlled by Microsoft.\nNot what I intended at all.\n\u0026mdash; Elon Musk (@elonmusk) February 17, 2023 結局BaiduもLLMモデルを発表しました。しかし内部の噂によると、完成したモデルは中国の諺をあまり知らないのだとか。情報統制下の国ではたとえ自国の言語でも良いクオリティのモデルは作れないのかもしれません。 ### 倫理的問題 ChatGPTはあまりに凄すぎたのか、倫理的な問題から法整備等の準備をすべきだという声が上がっています。イーロンマスクやAI研究者達が[今日から6ヶ月間AI研究を完全停止して、AIの使い方について議論すべきだという署名を開始したりもしています](https://time.com/6266679/musk-ai-open-letter/)。(私はこの運動には懐疑的です) 結局イーロンはTruthGPTなるものを開発すると発表しました。この署名は本当にくだらないもので、ChatGPTに先を越された人たちの負け惜しみでしかなかったようです。 また、解決されつつありますが、InjectionやJail breakといった手法でChatGPTがハックされてしまう可能性があります。GPT4でアプリ開発をしている人たちは要注意です。 あと、DeeplやChatGPTは入力した内容を学習に使用します。個人情報などは絶対に入力してはいけません。・・・といっても入力する人が絶対いるので、これもリスクでしょうね。APIなら収集していないようです。 また、古典的なステレオタイプに基づいてものを言う癖がある点も海外では問題視されています。試しにBingなどで日本人の画像を生成してみてください。とんでもないアジア人への偏見だなって思うような、細くつり上がった目・飛び出た頬骨・ふっくらした輪郭と体型になります。 他にも倫理的問題を挙げればキリが無いと思いますが、**「AIがヒトを支配する」とかいった、いつ起こるか予想できないほど遠い未来の話と、Hallucinationのような現実的な話は切り離して考える必要があります。**この辺をごっちゃにして考えてしまっている人をSNSでよく見かけます。 ## 最後に 一ヶ月前に書いた文章をかき集めたので無いようがとっちらかってしまいました。 最近、色々な方からChatGPTに関して質問をされますが、あ～まだChatGPTへの誤解は大きいな～と思うことが多いので、いずれ包括的な解説記事も書こうと思っています。 ではまた！ ","date":"2023-05-04T00:00:00Z","permalink":"https://snitch0.github.io/p/ai-post-prompting/","title":"AI新時代の2023年を生き抜くためにAIを学ぶ③"},{"content":"この記事のテーマ ChatGPTの時代が来てるな、と実感してから二週間。これが活用できないと社会的に死ぬというかなり強い危機感によりAIを活用する方法を調べていました。\nAIを活用することは即ちプロンプティングスキルを伸ばすということです。\nブロンプティングとはAIへの命令文のことですが、命令の仕方でAIが用意してくれる情報の質が大きく変わってきます。それゆえ、プロンプティングを学ぶ必要があるのです。\nそしてこの二週間を様々なサイトでプロンプティングを勉強した末、私が行き着いた答え。それは、AIが「全く空気が読めない、お節介だけど、20~30歳くらいの超賢い社会人」であると想定して話すことです。\n今回はプロンプティングについて勉強をして重要だと思ったことを列挙しつつ、私なりのAIとの接し方にどうやって行き着いたのか、まとめてみようと思います。\nプロンプティング プロンプティングとはなんぞや プロンプティングとはAIに対して指示を出す命令文のことで、AIのパフォーマンスや出力品質に大きく影響します。ChatGPTに「ブログを書いて」とか「メールの返信文を考えて」などという依頼をしている人がそれなりにいると思われますが、良い指示の出し方をすると目に見えて優れた結果を得られるようになります。人間と一緒で、言い方が大事です。\n画像生成AIとして有名なMidjourneyを例に取りましょう。たとえばクリスマスツリーを擬人化したいとします。ちなみにこのお題は、妻に「何の画像が欲しい？」と聞いたらでてきた謎のお題です。\nまず最初にそのまま指令(プロンプト)を投げてみます。\n1 /imagine Anthropomorphic Christmat tree 結構気持ち悪い画像ができあがりました👾私が想像する擬人化クリスマスツリーはかわいい感じのイラスト系だったので、ちょっと違和感があります。今度はプロンプティングを活用しつつ詳しい指示を与えてみます。\n1 /imagine Anthropomorphic Christmat tree, cel anime, manga, cute, friendly, smooth, white background これだけで何かのコラボキャンペーンのイラストとして使えそうな感じになりました。このように、自分が思う必要な要素をどんどん継ぎ足して理想の画像を作るのがMidjourneyの面白さです。そして、「これを入れるとこうなる」みたいなイディオムを活用することがプロンプティングに相当します。ちなみに、cel animeは日本っぽいアニメのテイストを表現する単語です。\nちなみに、Bingとdalleに書かせると以下のようになりました。Bingいいなあ🤔\nでは、ChatGPTではどうか？ChatGPTも昨年末に発表されて以来、たくさんのプロンプティング研究がされています。何を隠そう、ChatGPTの開発元であるOpenAI自身が、このプロンプティングの方法について研究し、論文にまとめているくらいです。\n今回は以下の3通りのパターンでプロンプティングのコツをまとめてみたいと思います。\n以下の文章の大半はChatGPTに書かせました。どうやってこれを出したかについても言及します。 明確な指示 AIに求めるタスクや回答を具体的に明示することで、曖昧さを減らし、より適切な結果を得ることができます。指示が明確であればあるほど、AIはユーザーの期待に沿った回答を生成しやすくなります。\n例:\n不明確な指示: 「有名な建築物について教えて。」\nクリックして開く 世界にはたくさんの有名な建築物があります。ここではいくつかの例を挙げます：\nエッフェル塔 (フランス) - この象徴的な鉄の塔は、1889年のパリ万博を記念して建てられました。高さは330メートルで、現在もパリのシンボルとして親しまれています。\n自由の女神像 (アメリカ合衆国) - この巨大な銅像は、フランスがアメリカ合衆国の独立100周年を記念して贈呈したもので、ニューヨーク市のリバティ島に立っています。\nコロッセオ (イタリア) - ローマ帝国時代に建てられたこの円形闘技場は、古代ローマの建築技術の傑作とされています。現在は観光名所として人気があります。\nグレートウォール (中国) - この古代の城壁は、中国の北部を東西に横切るように伸びており、その長さは合計で2万キロメートル以上にもなります。防衛目的で建設されましたが、現在は世界遺産として観光客に人気です。\nピラミッド (エジプト) - ギザのピラミッドは、古代エジプトの王家の墓として建てられた建築物で、現存する古代世界の七不思議のうちのひとつです。\nシドニー・オペラハウス (オーストラリア) - オーストラリアのシドニー港に位置するこの建築物は、20世紀の建築の傑作とされており、独特の形状が特徴です。\nタージ・マハル (インド) - この白い大理石の建築物は、インドのアーグラに位置し、17世紀にムガル皇帝シャー・ジャハーンが妻のために建てた墓所です。\nこれらの他にも、世界各地に様々な有名な建築物が存在しています。建築や歴史に興味があるなら、これらの素晴らしい建築物を訪れることをお勧めします。\n明確な指示: 「フランスのエッフェル塔の歴史と建設に関する情報を教えてください。」\nクリックして開く エッフェル塔は、フランスの首都パリにある有名な建築物で、1889年に建設されました。当時、フランスはパリ万博（エクスポ）を開催することが決まっており、その目玉となる斬新な建築物が求められていました。エッフェル塔は、その目的を果たすべく建てられたものです。\nエッフェル塔の設計者は、フランスの建築家と技術者であるガストン・エッフェルです。彼の設計による塔は、鉄を主材料とした構造物で、全高は約330メートルです。当時、これほどの高さを持つ建築物は他になく、世界最高の建造物として有名になりました。その後、1930年にニューヨークのクライスラービルが完成するまで、エッフェル塔は世界一高い建造物でした。\nエッフェル塔の建設は、1887年に始まり、1889年に完成しました。建設には約2年と2ヵ月の時間がかかり、7000トンもの鉄と250万本のリベットが使用されました。建設には、300人の労働者が働き、幸いにも建設中の事故は1件しか報告されませんでした。\n当初、エッフェル塔は一時的な建築物として計画されており、20年後に解体されることが予定されていました。しかし、その後の技術革新により、無線通信のアンテナとして利用されるようになり、解体されることはありませんでした。エッフェル塔はその後も、観光名所や科学研究の場として活用されています。\n現在、エッフェル塔はフランスやパリの象徴とされ、年間約700万人の観光客が訪れる人気の観光地です。展望台からは、パリ市内の素晴らしい景色を楽しむことができます。\n不明確な指示では、AIがどの建築物について情報を提供すべきか分かりません。一方、明確な指示では、具体的な建築物（エッフェル塔）とその情報の範囲（歴史と建設）がはっきりしているため、AIは適切な回答を提供しやすくなります。\nこれは即ち、事前に我々がどんな指示を与えるかについて詳細に考えておく必要があるということを意味していると思います。\n資料作成の際には、とりあえずファイルを作り始めてから考えると言うこともありますが、これからの時代、作業時間は大幅に短縮されますので、スタート時点で完成形を詳細にイメージしておく必要があるのではないでしょうか？\n思考の連鎖 プロンプトエンジニア達の間ではCOT: Chain of Thoughtと呼ばれるやり方があります。\nこの方法ではQ\u0026amp;Aのパターンを例示して見せてやることで、思考を順序だてて行わせる方法です。嘘をつきがちなChatGPTの虚言癖を治し、論理的に正しいことを言わせるには有効な方法です。\nたとえば、子供に何かを教えようとしたとき、クイズを出したとします。しかし子供はそれにうまく答えることが出来ない。そんなとき、「ばかだなあ」とか「不正解。正しくはこうだ。」と言うのはひどい親だと思います。私だったら「うーん、ちょっと違う。この場合だったらどうだろう？」と別の例を示して、自分で真理にたどり着けるように誘導してやります。\nAIにそこまで気を遣う必要があるのか？と最初は私も思いましたが、AIとのプロンプトも一種のコミュニケーションと考えれば納得できるはずです。。\nステップバイステップ また、2023年3月24日の日経電子版でも「ChatGPTを賢くする呪文」として紹介されていたのがLet's think step by stepです。これを文末に付けるだけで、結果が改善することがあります。\n非常にシンプルですが、この呪文はChatGPTが苦手とする算数の計算などで、効果を発揮することが知られています。ChatGPTはなぜか単純な四則演算を頻繁に間違えるのですが、そういった計算を一つ一つのステップごとに分けて論理的に考えさせるのです。\nこの手法はZero Shot Chain of Thoughtとも呼ばれます。\n実務に活かすならば、例えば上司にメールを送りたい時、上司がどういう人物で、私がどういう間柄なのか、そして上司には何を伝えたいのか、どういう背景情報があったのか？ということを事細かに順序を立てて説明する必要があるということです。\n相手が人間でも同じですよね。丁寧すぎるくらいに順序だててお願いをすれば意思疎通に齟齬は起きにくいということです。\nまとめ というわけで、今回はChatGPTのプロンプティングについて調べました。いろいろなサイトを参考にして調べた結論としては、相手を人間だと思って丁寧にお願いをすることが重要だと思いました。\nもちろん丁寧というのは丁寧な口調で言えということではなく、順序立てて必要な情報を省略せずに伝えることです。\nこうして考えてみると、ChatGPT対するプロンプティングというのは、人とのコミュニケーションと全く同じということです。相手がAIだと侮って適当な命令をすれば自分の希望道りの結果は得られませんし、相手が大切な人だと思って丁寧に一個ずつ説明すれば、非常に良い結果が返ってくることがあります。\n部下や後輩に対しても同じですよね。順序立てて説明しないと、そりゃわからないよな、と、なんか反省してしまいました。\n現状のChatGPTは冒頭で述べたとおり、「全く空気が読めない、お節介だけど、20~30歳くらいの超賢い社会人」っていう感じかなと思いました。これからもChatGPTはどんどん進化していくと思いますが、楽しみな反面、将来どうなってしまうんだろうという不安もありますね。。\n参考にしたサイト Learn Prompting\n非常に分かりやすくCoTやZero shot Promptingについて説明している。Jail breakingなどのリスクに関する情報も手厚い。\nAwesome ChatGPT Prompts\nロール設定に特化したプロンプト紹介レポジトリ。\n215+ ChatGPT Prompts you Can\u0026rsquo;t Miss To Try Out In 2023\nめっちゃくちゃたくさんのプロンプトパターンを紹介しているが、特段テクニカルではない。 しかし、データサイエンス用のプロンプトなどは「こういうpythonコードが書けるのか」という発見があった。\n","date":"2023-03-26T00:00:00Z","permalink":"https://snitch0.github.io/p/ai-prompting/","title":"AI新時代の2023年を生き抜くためにAIを学ぶ②"},{"content":"空前のAIブーム この記事にたどり着いた方々には言うまでも無いと思うけど、記事作成時点ではGPT-4が発表された直後で、MicrosoftやGoogleが自社プロダクトにAIコンテンツ作成機能を標準搭載することを発表するなど、大盛り上がりです。\n昨年12月にChatGPTが公開されてちょっと試した時の感想は、「なんか凄まじく自然な会話してくるけど、こいつ結構嘘つくな」でした。息をするかの如く嘘を吐くため、まだシンギュラリティとは言えないかな～と思っていました。\nちなみに、シンギュラリティを「人工知能が人類を越えた瞬間」と定義したのはレイ・カーツワイルで、 著書「シンギュラリティは近い　人類が生命を超越するとき(2016)」がもとになっているらしい。今Amazonでポチった。後で読む。 今年に入ってからは「ChatGPTでこんなことさせてみた」系の記事が増えてきて、2月末くらいには\u0026quot;Prompting\u0026quot;(欲しい情報をAIから引き出すための、良い質問の仕方)みたいなものが成熟してきたように思います。\nこの時点ですら私はまだ懐疑的で、いずれAIは質問の意図もうまく汲んでくれるようになるんだからPromptingを研究するなんて時間の無駄だろうと思っていました。だからChatGPTは遊び程度にしか使っていなかった。\nしかし三月に入って少々暇ができた折、NotionAIやPerplexity、Phindといったサービスに触れてみたところAIサービス使いこなせないと俺が失業するというか、完璧なPromptingで調教されたAIは既に俺の能力を上回っているという強い危機感を感じるまでに質が高かったので、慌てて勉強を始めました。\n今回検討したこと ⇒ 翻訳機 Promptingも勉強していますが、まずは足下の作業効率UPからはじめようと思い英語の翻訳に取り組むことにしました。\n私が英語翻訳機能を欲するときは以下のような時です。\nネットサーフィン時 ⇒ deeplのChrome拡張で満足している 論文を読みこむ時 ⇒ ちょこちょこdeepl使いつつ原文で読むのでChrome拡張で良い 論文探しをするとき ⇒ Inoreader上で日本語で素早くザッピングしたい ニュースサイトを読んでるとき ⇒ よほど読み込みたい場合でなければ日本語で素早く読みたい 一番改善したいのが、RSSリーダーのInoreaderでニュースを漁っている時。どうしても英語が母国語ではないので、英語タイトルが並ぶ目が滑るんですよね。\n今の自分のニーズとしてはそれなりにボリュームのある記事・論文をなんらかのアプリケーション上で、手っ取り早く読みたい(要旨が分かれば良い)という形に落ち着きそうなので、基本的にはDeeplコピペだとかChrome拡張を使うなどではなく、APIを使ってプログラムを走らせる前提で検討してみることにしました。\n翻訳機の候補者たち DeepL 翻訳といったらこれ！もう日本人研究者でDeepLを知らない人はいないのでは？\nDeepLが有名になる前は「みらい翻訳」というツールを良く使ってましたが、最近ではDeepLの方が使い勝手が良くなってしまいました。\n無料と有料のAPIが提供されています。無料でも500,000単語までいけるので、本格的に業務利用しない限り無料APIで事足りる可能性が十分あります。\n参考までに、ハリーポッターシリーズ全部の単語数を会わせても1,084,170単語であることを踏まえると、500,000単語はすさまじく多い気がする。 DeepLの難点は、やはり字数制限があるところでしょうか。実際に運用してみないと分からないものの、私がInoreaderでサブスクライブしているフィードを通じて目にする論文だけで週に500本くらい、海外ニュースサイトの記事は一日で1000本くらいあります。全部を全文翻訳しないにせよこれを全て翻訳したら大変なことになりそうです。\nOpenAI API ChatGPTをちょこちょこ使ってますが、翻訳もそれなりにできるそうなので試してみました。\nAPIは有料です。今回使用したモデルは1K token使っても$0.02。なーんだ安いじゃんと思いきや、トークンとはなんぞやと調べると、記事一本で普通に1K token使ってもいっちゃいそうです。普通にChatするだけなら文字数少ないのでトークンも少なくて済むのに、翻訳は大量の文章を投げざるを得ないのでコストが嵩んでしまう模様。\nちなみに、今回の検討で何度かネット記事をAPIに投げましたが、現時点での支払い額は$0.11となっています。お試しでこれくらいなので先行きが不安です・・・\nNotionAI NotionAIはライティングツールのNotionで使えるツールです。文章の要約、翻訳、あるいはゼロからの記事作成などが可能なサービスで、既存のNotionプランとは別に$ 10/mo.(年払いディスカウント有)がかかります。\n私はもう二三年くらいNotionを愛用していて、proプランに課金し続けていて、タスク管理やアイデアノート、Wordに起こす前の草稿作成などに使っています。JTC企業研究員という仕事柄、ガチの業務文書はNotionに書かないようにしていましたが、ボヤっとした備忘録的な日誌として業務内容を書いたりはしていました。\nそんなNotionにもAI執筆が搭載されたわけですが、最近のMicrosoftやGoogleのムーブを少し先取りしていたような感じで、リリース当初は結構斬新な機能だったと思います。この文章を表に変換、みたいな操作ができますからね。少し使ってめちゃくちゃ便利だと思ったので即課金しました。\nいざ翻訳テスト！ 今回は適当な新聞記事を選んできました。選んだのはMeta社がTwitterライクアプリを作成中？ということを報じた記事です。\n権利的に配慮して、冒頭だけを引用します。\nMeta’s Developing a Decentralized Twitter Alternative, According to Reports\nWith many Twitter users unhappy about the platform’s changes under Elon Musk, and amid a growing push towards a new approach to social networking, with alternative systems of moderation and management, Meta is looking to seize the opportunity, by launching its own, Twitter-like social app, which will be focused on short, text-based updates.\nAs reported by Platformer and MoneyControl, Meta’s developing a new platform, currently titled ‘P92’, which sounds very similar to a Twitter feed, and interestingly, would be decentralized, aligning with the new wave social media push.\n久方ぶりに自力で日本語訳を試みます。\nメタ社が分散型ツイッター代替アプリを開発中、報道\nイーロンマスクのもとでTwitterというプラットフォームが変わってしまったことを多くのTwitterユーザーが嘆いている今の状況、そして新しい形のモデレーションやマネージメントシステムをもったソーシャルネットワーキングの新しいアプローチの開発を迫られている状況で、メタ社はTwitterライクなソーシャルアプリを自社でローンチする機会を掴もうとしています。このアプリは短文の、テキストベースの更新に焦点を当てられたものになるでしょう。\nPlatformerとMoneyControlで報じられたように、メタ社は今のところ「P92」と名付けられている新しいプラットフォームを開発中です。これはTwitterのフィードに非常によく似たものになりそうであり、また興味深いことに分散型であり、ソーシャルメディアの新しいトレンドの波に乗ったものになると言えるかもしれません。\n英語で書かれた記事を頻繁に読むわけではないのですが、上から下まで一読できるような文法をあえて使っているのかな、という気がしました。口語的というか。\nでは、この文章をAIに投げて翻訳させてみます。\nDeepL まずDeepL APIを使ったバージョンです。今回はフリー版を使っての実装です。なお、このコードはChatGPTが生成したコードをほんの少しだけ修正しただけのものです。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 import requests # type: ignore import argparse parser = argparse.ArgumentParser(description=\u0026#34;Translation tool using DeepL API\u0026#34;) parser.add_argument(\u0026#34;-i\u0026#34;, type=str, help=\u0026#34;Input file path\u0026#34;) parser.add_argument(\u0026#34;-o\u0026#34;, type=str, help=\u0026#34;Output file path\u0026#34;) args = parser.parse_args() with open(args.i, \u0026#34;r\u0026#34;) as f: text = f.read() with open(\u0026#34;deepl.key\u0026#34;, \u0026#34;r\u0026#34;) as f: auth_key = f.read().strip() target_language = \u0026#34;JA\u0026#34; source_language = \u0026#34;EN\u0026#34; url = \u0026#34;https://api-free.deepl.com/v2/translate\u0026#34; params = { \u0026#34;auth_key\u0026#34;: auth_key, \u0026#34;target_lang\u0026#34;: target_language, \u0026#34;source_lang\u0026#34;: source_language, \u0026#34;text\u0026#34;: text, } response = requests.post(url, data=params) translated_text = response.json()[\u0026#34;translations\u0026#34;][0][\u0026#34;text\u0026#34;] with open(args.o, \u0026#34;w\u0026#34;) as f: f.write(translated_text) DeepLのドキュメンテーションも読まずにコード実行したところ403エラー。調べたところフリー版と有料版とではURLが異なるらしく、そこだけ修正しました。\nDeepLライブラリを使った別の実装 記事書きながら公式のドキュメント読んでたら気づきましたが、python用の公式ライブラリがあったんですね😢\nこちらの方が簡単そうだったので、サクッと実装してみました。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import deepl import argparse parser = argparse.ArgumentParser(description=\u0026#34;Translation tool using DeepL API\u0026#34;) parser.add_argument(\u0026#34;-i\u0026#34;, type=str, help=\u0026#34;Input file path\u0026#34;) parser.add_argument(\u0026#34;-o\u0026#34;, type=str, help=\u0026#34;Output file path\u0026#34;) args = parser.parse_args() with open(args.i, \u0026#34;r\u0026#34;) as f: text = f.read() with open(\u0026#34;deepl.key\u0026#34;, \u0026#34;r\u0026#34;) as f: auth_key = f.read().strip() translator = deepl.Translator(auth_key) target_language = \u0026#34;JA\u0026#34; result = translator.translate_text(text, target_lang=target_language) with open(args.o, \u0026#34;w\u0026#34;) as f: f.write(result.text) 非常にpythonicで良い実装になったと思います。\n結果 Metaが分散型Twitterの代替案を開発中との報道あり\nイーロン・マスクのもとでのTwitterの変化に不満を持つユーザーが多い中、モデレーションや管理システムなど新しいソーシャルネットワークのあり方を模索する声が高まる中、メタは、短いテキストベースの更新に焦点を当てた独自のTwitterライクなソーシャルアプリを発表し、この機会を捉えようと考えています。\nPlatformerやMoneyControlが報じたように、Metaは現在「P92」と題された新しいプラットフォームを開発中で、Twitterフィードに非常に似ているように聞こえるが、興味深いことに、分散型であり、新しい波のソーシャルメディアの推進に沿うものである。\n完璧です:star2: ところどころ自分の翻訳がおかしいところに気づかされます。\n細かいところの翻訳漏れがなく、タイトルも記事っぽい言い回しへと自動で言い換えているところが素晴らしいと思います。\n全く問題ないので、普段使いに採用しても全く問題なし。\nChatGPT OpenAIのAPIには様々なモデルが用意されています。はじめはGPT-3.5のdavinciを使って試しましたが、なぜか長文の結果を出力することができず途中で途切れてしまったため、GPT-3.5-turboを使用しました。前者は一つのプロンプトだけを投げる用、後者は対話のプロンプト形式用です。以下のコードもChatGPTにて生成したコードを少しだけ改変したものです。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 import openai import argparse openai.api_key_path = \u0026#34;api.key\u0026#34; parser = argparse.ArgumentParser(description=\u0026#34;Translation tool using OpenAI-api\u0026#34;) parser.add_argument(\u0026#34;-i\u0026#34;, type=str, help=\u0026#34;Input file path\u0026#34;) parser.add_argument(\u0026#34;-o\u0026#34;, type=str, help=\u0026#34;Output file path\u0026#34;) parser.add_argument(\u0026#34;--model\u0026#34;, default=\u0026#34;text-davinci-002\u0026#34;) args = parser.parse_args() def translate_text(input_text): response = openai.ChatCompletion.create( model=\u0026#34;gpt-3.5-turbo\u0026#34;, messages=[ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;あなたはプロの翻訳家です。\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: f\u0026#34;以下の文章を英語から日本語に翻訳してください。 {input_text}\u0026#34;}, ], ) return response[\u0026#34;choices\u0026#34;][0][\u0026#34;message\u0026#34;][\u0026#34;content\u0026#34;].strip() with open(args.i, \u0026#34;r\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: input_text = f.read() translated_text = translate_text(input_text) with open(args.o, \u0026#34;w\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: f.write(translated_text) 結果 報道によると、Meta社は分散型のTwitterの代替案を開発しています。\nElon Muskの下でプラットフォームの変更に不満を持つTwitterユーザーが多く、代替的なモデレーションや管理システムに向けた押しの中で、Meta社は自社のTwitterライクなソーシャルアプリを立ち上げることでこの機会をつかもうとしています。\nPlatformerやMoneyControlによると、Meta社は現在「P92」という名称の新しいプラットフォームを開発中で、Twitterフィードに非常に似ており、興味深いことに分散型であり、新しいソーシャルメディアの波に合致しています。\nDeepLに比べるとワンランクダウンした感じがします。しかし、Google Translateに比べたらよっぽどマシな性能です。\n「～に向けた押しの中で」といか、「新しいソーシャルメディアの波に合致しています」という部分は翻訳に苦労していそう。\nとは言えこれは全然アリです。普段使い用のAPIにしても良いくらい。\nNotionAI NotionAIはNotionのページ内で起動します。APIでは使えないので比較対象にならなそうですが、「記事をNotionにスクラップして、NotoinAPIで自動翻訳」という荒技が可能です。これはこれで実用的なソリューション。\nNotionはProアカウントにアップグレードすることで無制限に画像等をアップロードできるようになります。インターネット記事をスクラップし放題になるというこの恩恵があるから私はお金を払い続けています。 結果 報道によると、Metaは分散型のTwitter代替アプリを開発しているとのことです。\nElon Muskの下でプラットフォームの変更に不満を持つ多くのTwitterユーザーや、モデレーションや管理の新しいアプローチに向けた新しいソーシャルネットワーキングシステムの成長の中、Metaは機会をつかむために、短いテキストベースの更新に焦点を当てたTwitterのようなソーシャルアプリを立ち上げることを計画しているようです。\nPlatformerやMoneyControlによると、Metaは現在「P92」というタイトルの新しいプラットフォームを開発中で、Twitterのフィードに非常に似ており、興味深いことに分散型になる予定で、新しいソーシャルメディアの流れと一致しています。\n翻訳内容は間違ってはいないのですが、人に読ませる文章としてはどこかぎこちない。というか、一読してもなんか頭に入ってこない。\nElon Muskの下でプラットフォームの変更に不満を持つ多くのTwitterユーザーや\nこの文章は本来、「～という状況」かつ「～という状況」の中で「MetaはTwitter代替アプリを開発」という長い一文の冒頭部分なので、「～や」と次に続く文章を示唆する助詞を使うと読み手にはわかりにくくなってしまいますよね。これでは実用レベルとはいえません。\n番外編 Google Translate 結果 「Google Translateは使い物にならん」前提で書いてきましたが、実際のところどうなんでしょう？\n気になったので試してみました。\n報告によると、Meta は分散型 Twitter の代替手段を開発中\n多くの Twitter ユーザーが Elon Musk の下でのプラットフォームの変更に不満を持っており、モデレーションと管理の代替システムを使用したソーシャル ネットワーキングへの新しいアプローチへの圧力が高まる中で、Meta は独自の Twitter のようなサー\u0026gt;ビスを開始することで、この機会をつかもうとしています。 短いテキストベースの更新に焦点を当てたソーシャルアプリ。\nPlatformer と MoneyControl によって報告されたように、Meta は現在「P92」というタイトルの新しいプラットフォームを開発しています。これは Twitter フィードに非常に似ており、興味深いことに、新しい波のソーシャル メディア プッシュに合わせて分散化されるでしょう。\n意外に悪くない・・・？と思いきや、一番肝心の「分散型」というキーワードを知らないせいか、かんか直訳感があります。\nNotionAIよりはすらすら読めるような気がするような・・・🤔？\n「新しい波のソーシャル　メディア　プッシュに会わせて分散化されるでしょう」\nにしても、この文章はいくらなんでも謎ｗ　Google Translateは相変わらずな感じ。\n結論:やっぱりDeepLが最強 DeepLは読みやすいし、内容がすらすら頭に入ってくる。それ以外は読んでいくと途中でつまづくような、そんな違和感がありました。\nOpenAIのAPIも今回初めて使ってみましたが、意外にお金がかかることに気がつきました。本格的に業務利用するまでは控えておこう。\n今度はDeepLAPIでInoreaderのヘッドラインを自動翻訳する仕組みを作りたい。\n","date":"2023-03-18T00:00:00Z","permalink":"https://snitch0.github.io/p/ai-translate/","title":"AI新時代の2023年を生き抜くためにAIを学ぶ①"},{"content":"この記事は自分のための備忘録です メインブログは執筆コストが高すぎるので、気軽にかけるこちらのHugoブログへコンテンツを集約しようと画策しています。\nこちらで積極的な記事執筆に従事すべく、hugo-stackthemeにて定義されているスニペットやHugoそのもので定義されているスニペットをまとめておきます。あくまで自分用なので網羅はしていません。\n自分のための備忘録ですが、hugo-stack themeをお使いの方の参考にもなれば。\nショートコードなどは追加するかもしれないので、随時この記事を更新します。\nHugoで規定されているショートコード figure 1 {{\u0026lt; figure src=\u0026#34;https://d33wubrfki0l68.cloudfront.net/c38c7334cc3f23585738e40334284fddcaf03d5e/2e17c/images/hugo-logo-wide.svg\u0026#34; title=\u0026#34;Hugo logo\u0026#34; \u0026gt;}} Hugo logo Markdown記法で事足りることがほとんどなので、figureを使うことは無さそうです。\ngist gistは今回初めて使ったくらいなので、これも使うことは無いかも。使い方は簡単。\nhighlight 1 2 3 {{\u0026lt; highlight python \u0026gt;}} ... {{\u0026lt; /highlight \u0026gt;}} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def bubbleSort(array): # loop to access each array element for i in range(len(array)): # loop to compare array elements for j in range(0, len(array) - i - 1): # compare two adjacent elements # change \u0026gt; to \u0026lt; to sort in descending order if array[j] \u0026gt; array[j + 1]: # swapping elements if elements # are not in the intended order array[j], array[j+1] = array[j+1], array[j] return array data = [-2, 45, 0, 11, -9] sorted_data = bubbleSort(data) print(\u0026#39;Sorted Array in Ascending Order:\u0026#39;) print(sorted_data) ※AIが生成したコードなので間違ってるかもしれません(見た限り合ってるっぽいけど)\nこれもmarkdown記法で足りる。本当は行ハイライトなども可能ですが、stackテーマとは相性が悪いのか行番号がずれてしまいます。\nref 1 [相模原サンキューキャンペーンの時の記事]({{\u0026lt; ref \u0026#34;2022-10-15-sagamihara-map/index.md\u0026#34; \u0026gt;}}) 相模原サンキューキャンペーンの時の記事\nサイト内リンクのURLを自動生成してくれるスニペット。\nこれ今まで全く活用してなかったけど、便利だし最適解だし使わなきゃだな。\nページ内リンクも使ってみたけど、残念ながらうまくジャンプしてくれませんでした。\ntweet 1 {{\u0026lt; tweet golang 1633151903352627207 \u0026gt;}} 🥳 Go 1.20.2 and 1.19.7 are released!\n🔐 Security: Includes a security fix for crypto/elliptic (CVE-2023-24532).\n🔈 Announcement: https://t.co/0R5yvEp6JL\n⬇️ Download: https://t.co/CxvhilnLor#golang pic.twitter.com/xlnHevMUGv\n\u0026mdash; Go (@golang) March 7, 2023 ツイート引用もwordpressだと何かと面倒ですが、hugoのショートコードならかなり簡単に。\nこのブログで仕様しているstackテーマでは中心寄せのcssになっていなかったので、以下のように少し改変しました。\n1 2 3 4 5 6 .twitter-tweet { color: var(--card-text-color-main); display:block; margin-left:auto; margin-right:auto; } youtube 1 {{\u0026lt; youtube weLaDoGBlxM \u0026gt;}} youtubeもidを入れるだけでページ内ビュワーが作られます。ショート動画は左右に暗幕が出来てしまうので、あまり見栄えが良くないかも。\n自分で追加したショートコード message box 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 {{% hint info %}} Info box. {{% /hint %}} {{% hint warning %}} Warning box. {{% /hint %}} {{% hint danger %}} Danger box. {{% /hint %}} {{% hint normal %}} Normal box. {{% /hint %}} Info box.P\nWarning box.\nDanger box.\nNormal box.\nblog-card 1 {{\u0026lt; blog-card url=\u0026#34;https://www.youtube.com\u0026#34; \u0026gt;}} オシャンなblogカードが欲しくて過去に作ったもの。はてなのAPIを使って実装しています。\naccordion 1 2 3 4 5 {{\u0026lt; accordion title=\u0026#34;クリックで展開\u0026#34; \u0026gt;}} {{\u0026lt; highlight python\u0026gt;}} import pandas as pd {{\u0026lt; /highlight \u0026gt;}} {{\u0026lt; /accordion \u0026gt;}} クリックで展開 1 import pandas as pd gkzz.devさんのブログを参考にさせていただきました。\nスニペット ショートコードの記法とは異なるが、html tagのようなスニペットが使える。\nmark 1 文章の中でも\u0026lt;mark\u0026gt;**特に強調したい部分**\u0026lt;/mark\u0026gt;をハイライトできる。 文章の中でも特に強調したい部分をハイライトできる。\nsub, sup 1 文章の中で\u0026lt;sub\u0026gt;下付き\u0026lt;/sub\u0026gt;や\u0026lt;sup\u0026gt;上付き\u0026lt;/sup\u0026gt;を使うことが出来る。 文章の中で下付きや上付きを使うことが出来る。\nkbd 1 \u0026lt;kbd\u0026gt;Ctrl\u0026lt;/kbd\u0026gt;キーを押しながら\u0026lt;kbd\u0026gt;C\u0026lt;/kbd\u0026gt;を押す Ctrlキーを押しながらCを押す\n","date":"2023-03-11T00:00:00Z","permalink":"https://snitch0.github.io/p/hugo-blog-snippets/","title":"このブログの書き方"},{"content":"ごあいさつ 公私ともに非常にバタバタした。いやー、本当に忙しかった！更新してなかった間にも色々気になった商品や本などがあるのでいずれ書き記していきたい。\n今回は気になっていたものの一つ、Neovimの開発環境をサクッと作るnvim-kickstartレポジトリを試す。レポジトリのメンテナ、youtubeの解説者はNeovimデベロッパーのTJ DeVries。\nNeovimとnvim-kickstart Neovimはコンソール上で動作するウルトラ軽量なテキストエディタ。かつてはEmacsとVimとの間でテキストエディタ戦争があったらしいが、Visual Studio Codeが登場したことにより多くの人はVSCodeへ移行し、戦争は終結した。\nしかしVSCodeを使わないとチームでハブられる昨今でも、マウスやカーソルキーを使うこと無くスピーディーなテキスト編集が可能なVimエディタは根強い人気があり、コアなユーザーを中心にVimは使われ続けている。\nNeovimはVimからフォークしたプロジェクトであり、VimのほとんどをLuaというプログラミング言語で書き換えたものである。独自のVimscript言語によりカスタマイズ・プラグイン開発をするVimは年々ガラパゴス化しているとの批判があるのに対して、現代的なプログラミング言語のLuaでエディタを自由自在にカスタマイズできるNeovimは柔軟かつスピーディーな開発体制もあって年々人気が高まっている。\n2022年のStack Overflowにおけるアンケート調査ではNeovimが「最もユーザーに愛されているエディタ」になったことも話題になっていた。\nNeovimの最大の特長はユーザーの好みに合わせていくらでもカスタマイズできる点であり、Lua言語で設定ファイルを作るのはさながら波平が盆栽を手入れするかのよう。コーディングを効率化するためにテキストエディタの設定にこだわり休日が溶ける、なんてことはザラである。\n「テキストエディタなんぞに時間をかけるなんて本末転倒じゃないか」と思う人も少なくないが、nvim-kickstartはそんな人のためにあるのかもしれない。このレポジトリではNeovimにLanguage Server Protocol(LSP)やカラースキームなどの小難しい設定がほとんど完了した状態の設定ファイルが配布されている。\n今回はこのレポジトリを使ってサクッとNeovimを導入しつつ、nvim-kickstartのデフォルト設定を眺めていく。\nnvim-kickstartのクローンして一瞬で環境構築 nvimはインストール済みの前提で進める。 もしインストールしてなかったらGitHubからnightlyをインストールして好きなところに展開するも良いし、bobを入れておけばnightlyのアップデートが楽になるのでよりおすすめ。\n動画では「init.luaをコピペするだけで良い」と言っているが、現在ではinit.lua以外のファイルもあるのでクローンしてしまった方が良い。\n.config/nvimがNeovim設定ファイル置き場なので、そこにクローンする。\n1 2 3 cd ~/.config git clone git@github.com:nvim-lua/kickstart.nvim.git nvim クローンが終わったらnvimコマンドでNeovimを立ち上げる。すると早速パッケージマネージャのlazy.nvimとLSP関連のプラグインがDLされる。以上で終わり。\n今までNeovimの設定ファイルを何度も自分で書き直してきたが、LDP関連のところが本当に躓きやすい。 このレポジトリはクローンしたら立ち所にLSPが使えるようになるので、本当に初心者には良い。\nkickstartの中身を理解する kickstartのコンセプトはkickstartの中身を理解してから自分なりにアレンジしてね、ということなので頑張って中身を理解していきたい。\nまずはどういう設定の仕方をしているのかと、デフォルトのキーマップなどから理解しようと思う。\nlazy.nvimについて Neovimの醍醐味はプラグインを使って機能を拡張していくことだ。\n以前はpacker.nvimというプラグインマネージャーがスタンダードだったが、packer.nvimは6年の歴史があり「そろそろ新しいのが出てきても良いんじゃ無いか」という雰囲気だった。そこに登場したのがlazy.nvimで、これがpackerのインターフェースはそのままに、かゆいところに手が届くもんだから一気に乗り換えが進んでいる。\n\u0026hellip;ということは知ってたが、lazy.nvimは今回初めて使う。\n基本的な書き方は以下。\n1 2 3 4 5 6 7 8 9 10 11 12 require(\u0026#34;lazy\u0026#34;).setup( { \u0026#39;nvim-neo-tree/neo-tree.nvim\u0026#39;, branch = \u0026#39;v2.x\u0026#39;, config = function () require(\u0026#39;neo-tree\u0026#39;).setup({ close_if_last_window = true, window = { width = 30, } } } )　ｎ packer.nvimとほとんど同じ使い方だが、微妙に引き数名が違う。移行ガイドが参考になる。\nname packer.nvimでの名称 使いどころ init setup インストール時に実行するコマンド dependencies requires 依存プラグイン version tag バージョン指定 keys keybindings 使い方が違う。 keysが特に使いやすい。ここでkey-bindingsを指定しておけば、nnoremapしなくてもよい。 nvim-kickstartではwhich-keyが最初から入っているので、キーマップはキーから始まるものに設定し、descにもわかりやすい説明文を書いておくと良い。 勝手にwhich-keyに反映されてくれる。\n1 2 3 4 5 6 7 8 { \u0026#39;iamcco/markdown-preview.nvim\u0026#39;, run = function() vim.fn[\u0026#39;mkdp#util#install\u0026#39;]() end, event = \u0026#34;BufRead\u0026#34;, keys = { {\u0026#34;\u0026lt;leader\u0026gt;mp\u0026#34;, \u0026#34;\u0026lt;Plug\u0026gt;MarkdownPreview\u0026#34;, desc = \u0026#34;Markdown Preview\u0026#34;} }, }, Telescopeを使ってNeovimを縦横無尽 動画では「キーマップが分からなくなったら:Telescope keymapsで確認できるぜ!」と言われている。これにより確認できるが、癖の無い、使いやすいキーマップをあらかじめセットしてくれている。\nTelescopeはNeovimにしかないプラグインで、fzfというファジーファインダーと組み合わせることで高速な検索が実現される。検索するのはファイル中の文字、ファイル名、関数名、とにかくなんでもあり。これもセットアップするにはTelescopeのドキュメントを読む必要があったのだが、kickstartでは環境構築済みである。なんとすばらしい。\ninit.luaを覗くと以下のキーマップが登録されていた。\nkeymap 機能 \u0026lt;leader\u0026gt;\u0026lt;space\u0026gt; 現在開いているバッファを探す \u0026lt;leader\u0026gt;? 最近開いたファイルを探す \u0026lt;leader\u0026gt;/ 現在のファイルでfuzzy search \u0026lt;leader\u0026gt;sf 現在のディレクトリでファイルを探す([S]earch [F]ile) \u0026lt;leader\u0026gt;sh ヘルプを探す([S]earch [H]elp) \u0026lt;leader\u0026gt;sw 現在カーソルのあっている単語を探す([S]earch [W]ord) \u0026lt;leader\u0026gt;sg フリーワード検索([S]earch [G]rep) \u0026lt;leader\u0026gt;sd Diagnosticsを検索([S]earch [D]iagnostics) なお\u0026lt;leader\u0026gt;キーはspaceキーに設定されている。\nTelescopeを使った拡張はまだまだこんなもんじゃない(はず)なので、良い使い方を見つけたらカスタムしていきたい。\ntreesitter treesitterは構文解析のプラグインである。「所詮シンタックスハイライトだけだろ?」と思っていたが、kickstartでは実に色々な活用がされていて目から鱗だった。treesitterでできるとは知らずにわざわざ別のプラグインを使ってた節もあったので、treesitterはきちんと勉強しようと思う。\nkeymap 機能 \u0026lt;c-space\u0026gt; 選択範囲を広げる \u0026lt;c-s\u0026gt; スコープを広げる \u0026lt;M-space\u0026gt; 選択範囲を狭める ]m 次の関数 ]m 次の関数 ]] 次のclass ]M 次の関数(outer) [[ 前のclass(outer) [] 前のclass [M 前の関数(outer) [[ 前のclass(outer) 以下はcやdなどの後に使うサブコマンド。\nサブコマンド 機能 aa Around parameter ia Inner parameter af Around function if Inner parameter ac Around class ic Inner class クラスや関数は言語によって扱いやすさが違うと思う。少なくともpythonを書いている間、ビジュアルモードでクラス全体を選択したいケースはあまり発生しない。\nLSP Language server protocol(LSP)は補完機能のあれ。Neovimをカスタムしまくってる人の画面を見ると良い感じのLSPが動いてたりするが、kickstartのLSPは必要最低限といった感じ。\nぶっちゃけNeovimでゴリゴリのコーディングをするつもりは最初から無く、VSCode Neovimを使ってVSCode用にNeovimを最適化することが目標なので、LSPまわりをカスタムする気は現状あまりない。\n以下のキーマップが入っていた。\nkeymap 機能 \u0026lt;leader\u0026gt;rn カーソルの変数・関数名をリネーム \u0026lt;leader\u0026gt;ca コードアクション(インポートを並び替えたりなど。LSPサーバーによる。) gd Go to definition gr Go to reference(Telescopeで立ち上がる) gI Go to Implementation \u0026lt;leader\u0026gt;D Type Definition(pythonならクラスの定義に飛ぶ) \u0026lt;leader\u0026gt;ds Document中のsymbolを全て表示(Telescopeで立ち上がる) K 関数などのドキュメンテーションをホバーで表示 \u0026lt;c-k\u0026gt; ↑とほぼ同じ gD Go to decleration \u0026lt;C-d\u0026gt; サジェストを下へスクロール \u0026lt;C-f\u0026gt; サジェストを上へスクロール \u0026lt;C-Space\u0026gt; サジェストを受け入れて補完する \u0026lt;Tab\u0026gt; 次の候補へ \u0026lt;S-Tab\u0026gt; 前の候補へ keymap 機能 \u0026lt;leader\u0026gt;wa ワークスペースにフォルダを作成([W]orkspace [A]dd Folder) \u0026lt;leader\u0026gt;wr ワークスペースのフォルダを削除([W]orkspace [R]emove Folder) \u0026lt;leader\u0026gt;wl ワークスペースのフォルダフルパスを表示 まとめ 今回はnvim-kickstartを導入してみて、モダンなNeovim設定に触れてみた。\nLazy.nvimの細かい使い方など、隅々までドキュメンテーション読まないと最新の書き方に追いつけないような部分もしっかり実装されているので、非常にためになった。 確か2022年暮れ～2023年明けくらいにこのレポジトリが発足したと思うが、継続的にコードはメンテナンスされているのでgit pullすれば常に最新情報に触れられるかもしれない。\n次回以降はkickstartをカスタムした内容をまとめる予定。\n","date":"2023-02-23T00:00:00Z","permalink":"https://snitch0.github.io/p/neovim-kickstart/","title":"nvim-kickstartで2023年のモダンなNeovim開発環境を手軽に作る"},{"content":"はじめに メインブログでは久しぶりの投稿です😄 (と言いつつサブブログにアップするかも) 試しに解説したQuartoブログの執筆が非常に快適なため、いずれ全ての記事をサブブログに移行することを検討中です。\nいずれ時間ができたらQuartoとHugoで静的ブログを開設する方法についても解説記事をアップしたいと思います💡\nさて、今回は相模原市の39キャンペーン加盟店のマップをRとPythonで作成します!\n相模原市39キャンペーンとは 年に一度相模原市が開催しているキャンペーンで、15,000円以上の消費をすれば市から3,900円がキャッシュバックされるという神キャンペーン!😇 しかも家族の頭数の分だけ申請可能で、誰の買い物でもOKという、ガバガバ神仕様。😇😇\nしかし、非常に残念なことに加盟店一覧情報はpdfファイルに書かれた情報しかありません･･･　このご時世にいくらなんでもお役所仕事すぎるだろ･･･ってことで私が代わりにマップを作って差し上げることにします。\n方針 今回の方針では、①pdfファイルから表データをスクレイピング、②抽出した住所データから緯度・経度情報をGoogleMapAPIを使って取得、③GoogleMapにプロット という流れでやっていきます。\n序盤のスクレイピングですが、便利なWebツールとか、似たようなライブラリ・パッケージが山ほどありますので、正直なんでも良いです🤚今回は結果がpandas.DataFrameとして返ってくるcamelotが便利そうだったので、これを採用しました。\n自分はあんまり地図データの取り回しをやったこと無かったのですが、瓜生さんの地図データ可視化のお話を昔から見させていただいた身からすれば「これはRの守備範囲だろうな」と、あまり下調べもせずRでの実装をすることにしました。\n作り方 pdfファイルから表データをスクレイピング camelotは今回調べて初めて使いましたが、非常にシンプルなAPIで使用できる上、かなり詳細な設定もできる模様。かなりテーブル抽出に特化していますが、非常に素晴らしいライブラリだと思います🚰\nファイル書き出しの際は、一ページに存在する表がバラバラに返ってくるため、大量のファイルに分割して書き出すことになります。どうせR側でこのあとpurrr::map_dfr()でもすれば結合できるので、気にしない😉\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import camelot import pandas as pd from pathlib import Path from tqdm import tqdm def extract_table(pdfpath: str): # ファイル名から区名を取得する ward = Path(pdfpath).name # テーブルを抽出する tables = camelot.read_pdf(pdfpath, pages=\u0026#34;all\u0026#34;) # 書き出し for index, table in enumerate(tqdm(tables)): table\\ .to_csv(f\u0026#34;data/{ward}_{index}.csv\u0026#34;, index=False) for p in [\u0026#34;中央区.pdf\u0026#34;, \u0026#34;南区.pdf\u0026#34;, \u0026#34;緑区.pdf\u0026#34;]: extract_table(p) 抽出できたので、とりあえずファイルを読んでみます。以降の解析はRを使うことにします。\n1 2 3 pacman::p_load(tidyverse) read_csv(\u0026#34;data/中央区.pdf_0.csv\u0026#34;) New names: Rows: 24 Columns: 7 ── Column specification ──────────────────────────────────────────────────────── Delimiter: \u0026quot;,\u0026quot; chr (7): ...1, 事業所（店舗等）名, 事業種別, 事業内容, 事業所所在地, 電話番号, PR・オトク情報... ℹ Use `spec()` to retrieve the full column specification for this data. ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. • `` -\u0026gt; `...1` # A tibble: 24 × 7 ...1 `事業所（店舗等）名` 事業種別 事業内容 事業…¹ 電話…² PR・…³ \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; 1 相生 GOGO 飲食業 \u0026quot;お酒飲みなが… 相生3-… 080-47… \u0026lt;NA\u0026gt; 2 \u0026lt;NA\u0026gt; U-Select相模原中央 小売業 \u0026quot;自動車(中古車… 相生2-… 042-75… \u0026lt;NA\u0026gt; 3 \u0026lt;NA\u0026gt; うなぎ処いわき 飲食業 \u0026quot;飲食業\u0026quot; 相生2-… 042-75… \u0026lt;NA\u0026gt; 4 \u0026lt;NA\u0026gt; （有）菅原塗装工房 その他 \u0026quot;住宅塗装\u0026quot; 相生3-… 042-70… \u0026lt;NA\u0026gt; 5 \u0026lt;NA\u0026gt; セブンイレブン相生店 小売業 \u0026quot;コンビニエン… 相生4-… 042-75… \u0026lt;NA\u0026gt; 6 \u0026lt;NA\u0026gt; せんざん相模原店 飲食業 \u0026quot;和食、海鮮料… 相生1-1 042-77… \u0026lt;NA\u0026gt; 7 \u0026lt;NA\u0026gt; ソニック相模原 小売業 \u0026quot;家電販売、電… 相生4-… 042-75… \u0026quot;お見… 8 \u0026lt;NA\u0026gt; 蕎麦とそばまえgenten 飲食業 \u0026quot;手打ち蕎麦屋… 相生1-… 042-76… \u0026lt;NA\u0026gt; 9 \u0026lt;NA\u0026gt; パティスリーフレジェ 小売業 \u0026quot;手作りケーキ… 相生3-… 042-75… \u0026quot;手作… 10 \u0026lt;NA\u0026gt; ヘアーサロン セオ サービス業 \u0026quot;理容業 カット… 相生4-… 042-75… \u0026lt;NA\u0026gt; # … with 14 more rows, and abbreviated variable names ¹​事業所所在地, ²​電話番号, # ³​`PR・オトク情報` # ℹ Use `print(n = ...)` to see more rows ちゃんと抽出できているようです。元々のデータでは一列目が結合されたセルになっているため、完全な表にしたいのならパディングをすべきですが、まあ使わないので放っておきます。\n抽出したデータをきれいにする とりあえず、データを全部結合してみます。\n1 2 3 4 5 6 7 8 9 df_joined \u0026lt;- fs::dir_ls(\u0026#34;data\u0026#34;) |\u0026gt; suppressMessages( map_dfr(function(x) { read_csv(x, show_col_types = FALSE) %\u0026gt;% select(2:ncol(.)) }) ) df_joined |\u0026gt; head() data/中央区.pdf_0.csv data/中央区.pdf_1.csv data/中央区.pdf_10.csv data/中央区.pdf_11.csv data/中央区.pdf_12.csv data/中央区.pdf_13.csv 結合は問題なくできています。事業社所在地の住所をGoogleGeometryAPIに投げれば緯度と経度が出せそうですが、できるなら「神奈川県相模原市??区」もついていた方が正確な検索結果を得られそうです。\n適当にこれをコーディングしてみます。今回はファイル名から区名を取り出しつつ、結合してみます。\n1 2 3 4 5 6 7 8 9 10 11 12 13 df_joined \u0026lt;- fs::dir_ls(\u0026#34;data\u0026#34;) |\u0026gt; map_dfr(function(x) { # \u0026#34;緑区.pdf_0.csv\u0026#34;から\u0026#34;緑区\u0026#34;を取り出す wald_name = fs::path_file(x) |\u0026gt; str_split(\u0026#34;\\\\.\u0026#34;) |\u0026gt; pluck(1) |\u0026gt; pluck(1) read_csv(x, show_col_types = FALSE, col_names = FALSE) |\u0026gt; magrittr::set_colnames(c(\u0026#34;area\u0026#34;, \u0026#34;事業所名\u0026#34;, \u0026#34;事業種別\u0026#34;, \u0026#34;事業内容\u0026#34;, \u0026#34;事業所所在地\u0026#34;, \u0026#34;電話番号\u0026#34;, \u0026#34;PR\u0026#34;)) %\u0026gt;% select(2:ncol(.)) |\u0026gt; mutate(adress = glue::glue(\u0026#34;神奈川県相模原市{wald_name}{事業所所在地}\u0026#34;)) }) プレビューしてみる。\n1 df_joined |\u0026gt; head() # A tibble: 6 × 7 事業所名 事業種別 事業内容 事業所…¹ 電話…² PR adress \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;glue\u0026gt; 1 事業所（店舗等）名 事業種別 \u0026quot;事業内容\u0026quot; 事業所… 電話番… PR・… 神奈… 2 GOGO 飲食業 \u0026quot;お酒飲みながら色… 相生3-4… 080-47… \u0026lt;NA\u0026gt; 神奈… 3 U-Select相模原中央 小売業 \u0026quot;自動車(中古車)の… 相生2-1… 042-75… \u0026lt;NA\u0026gt; 神奈… 4 うなぎ処いわき 飲食業 \u0026quot;飲食業\u0026quot; 相生2-1… 042-75… \u0026lt;NA\u0026gt; 神奈… 5 （有）菅原塗装工房 その他 \u0026quot;住宅塗装\u0026quot; 相生3-1… 042-70… \u0026lt;NA\u0026gt; 神奈… 6 セブンイレブン相生店 小売業 \u0026quot;コンビニエンスス… 相生4-1… 042-75… \u0026lt;NA\u0026gt; 神奈… # … with abbreviated variable names ¹​事業所所在地, ²​電話番号 途切れているので住所だけを抽出。\n1 df_joined |\u0026gt; select(adress) # A tibble: 2,021 × 1 adress \u0026lt;glue\u0026gt; 1 神奈川県相模原市中央区事業所所在地 2 神奈川県相模原市中央区相生3-4-20 3 神奈川県相模原市中央区相生2-1-1 4 神奈川県相模原市中央区相生2-16-6 5 神奈川県相模原市中央区相生3-13-10-1F-1 6 神奈川県相模原市中央区相生4-1-15 7 神奈川県相模原市中央区相生1-1 8 神奈川県相模原市中央区相生4-11-15 9 神奈川県相模原市中央区相生1-1-18　1F 10 神奈川県相模原市中央区相生3-14-14 # … with 2,011 more rows # ℹ Use `print(n = ...)` to see more rows よさそうです👌\nGoogleGeocodingAPIを使って住所から緯度・経度を出す ℹ️Info\nGoogleGeocodingAPIは従量課金の有料サービスです。1,000クエリで5.00USDとのことですので、今回のケースを有料でAPI叩いた場合約10USDくらい必要になります。 私は今回90日限定のフリー体験の範囲内で試しました。また、新規登録時に無料クレジットが300USDもらえたので、当分お金の心配はいらないのかなと思います。\n使い方はGoogle cloudでアカウントを作成し、コンソールに行き、プロジェクトを新規作成、プロジェクトを開いてライブラリに飛ぶとGoogle geocoding APIが有効化できます。APIキーは認証情報から確認できます。\n最初はgeocoding.jpを使う以下のようなコードを書きましたが、10秒に1回のクエリに制限する必要があったため、GoogleのAPIを使うことにしました。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 pacman::p_load(rvest) get_position \u0026lt;- function(adress) { url \u0026lt;- paste0(\u0026#34;https://www.geocoding.jp/api/?v=1.1\u0026amp;q=\u0026#34;, adress) lat \u0026lt;- read_html(url) |\u0026gt; html_nodes(\u0026#34;lat\u0026#34;) |\u0026gt; html_text() lng \u0026lt;- read_html(url) |\u0026gt; html_nodes(\u0026#34;lat\u0026#34;) |\u0026gt; html_text() lat \u0026lt;- if_else(is.na(lat), \u0026#34;0\u0026#34;, lat) lng \u0026lt;- if_else(is.na(lng), \u0026#34;0\u0026#34;, lng) # wait Sys.sleep(10) return(tibble(lat = lat, lng = lng)) } get_position_vec \u0026lt;- function(adress_vec) { adress_vec |\u0026gt; map_dfr(\\(vec) get_position(vec)) } で、以下が本題。\n1 library(ggmap) Google's Terms of Service: https://cloud.google.com/maps-platform/terms/. Please cite ggmap if you use it! See citation(\u0026quot;ggmap\u0026quot;) for details. Google cloud platformからAPIキーを取得します。とりあえず今回はgeocoding APIだけ取得すればOKです。\nここにAPIキーをハードコードするわけにはいかないので別ファイルから読み込んでますが、register_google(key = ******)に直接入力して問題ありません👍\n1 2 3 # APIキーはGCPから取得したもの key \u0026lt;- readChar(\u0026#34;API.key\u0026#34;, file.info(\u0026#34;API.key\u0026#34;)$size) register_google(key = key) ggmapパッケージはmutate_geocode()関数でお手軽に住所検索ができます。\n1 2 3 4 df_geo \u0026lt;- df_joined |\u0026gt; mutate_geocode(adress) df_geo |\u0026gt; write_csv(\u0026#34;sagamihara_geodata.csv\u0026#34;) 計算が無駄にならないように書き出しておいて・・・。\nできあがったファイルをみると、lonとlatという列が追加されています!　これが経度緯度のようです。 ここまで来ればあとはGooglemapに書き出すだけ😉\nRでGoogleMapにピンを立てる方法はちょっと分からなかったので、GoogleMapにオリジナルマップを作成する戦法をとりました。\nGoogleMapにピンたてる Googleのマイマップにいきます。\nここで新しい地図の作成⇒レイヤのインポートを選択し、先ほど出力したファイルを食わせます。\nするとマーカーのタイトルを選ぶよう言われるので、とりあえず事業所名にでも設定しておきます。 こうしてできたのが以下です!\nマイマップの埋め込みリンクを取得して貼り付ければ、こんな感じでブログに載せられるので便利ですね。\nまとめ 今回は以下の作業をプログラミングでやってみました。\npdf内にしかない住所情報を取得 GoogleGeocodingAPIを使って住所から座標を取得 Googleマップと組み合わせると地図データは色々遊べそうで、面白いですね😄\n相模原市にお住まいの方は、サンキューキャンペーンがあと一ヶ月あまりです!頑張って15,000円使いましょう!!\n","date":"2022-10-26T00:00:00Z","permalink":"https://snitch0.github.io/p/sagamihara-39-map/","title":"pdfファイルの住所情報を抽出してGoogleMapに表示させる"},{"content":"prep 1 pacman::p_load(tidyverse) (1) 二項分布の確率はdbinom()関数で生成できる。\n1 2 3 4 5 6 7 8 9 x \u0026lt;- seq(1:6) df_1 \u0026lt;- tibble( x = x, y = dbinom(x, size = 6, prob = 0.25) ) df_1 |\u0026gt; ggplot(aes(x, y)) + geom_point() + geom_line() 平均値と標準偏差を確率分布から求める。\n標準偏差を求める関数を作っておく。\n1 glue::glue(\u0026#34;mean is {sum(df_1$x * df_1$y)}\u0026#34;) mean is 1.5 1 2 3 4 val_mean \u0026lt;- sum(df_1$x * df_1$y) val_var \u0026lt;- sum((df_1$x)^2 * df_1$y) - val_mean^2 glue::glue(\u0026#34;variance is {val_var}\u0026#34;) variance is 1.125 二項分布の平均値、分散がそれぞれであることを利用した計算結果と一致する。\n1 glue::glue(\u0026#34;np = {6 * 0.25}\u0026#34;) np = 1.5 1 glue::glue(\u0026#34;npq = {6 * 0.25 * 0.75}\u0026#34;) npq = 1.125 (2) nとpが与えられた時の二項分布の平均と分散を求める関数を作成してみる。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 calc_binomial \u0026lt;- function(n, p) { x = seq(1, n, 1) y = dbinom(x, n, p) val_mean = sum(x * y) val_var = sum(x * x * y) - val_mean ^ 2 tibble(x = x, y = y) |\u0026gt; ggplot(aes(x, y)) + geom_line() + geom_point() + geom_segment(aes(x = val_mean, xend = val_mean, y = 0, yend = dbinom(val_mean, n, p))) + theme_bw() + ggtitle(glue::glue(\u0026#34;n = {n}, p = {p}\u0026#34;)) + annotate(\u0026#34;text\u0026#34;, x = val_mean + 10, y = max(y), label = glue::glue(\u0026#34;Mean = {val_mean}, Variance = {val_var}\u0026#34;)) } 1 calc_binomial(50, 0.5) 1 calc_binomial(100, 0.2) 1 calc_binomial(400, 0.2) 1 calc_binomial(900, 1/3) (3) 正確な硬貨を8回投げた時の表の出る回数は二項分布に従う。\n1 2 calc_binomial(8, 0.5) + xlim(c(0, 20)) (4) 二項分布の式、とは以下である。\n(a) $$ $$\n(b) 「たかだか２回」が解釈不能なので飛ばす。\n(c) $$ $$\n(d) 正確な硬貨を9回投げるとき、たかだか3回表が出る確率ってほんとなんなんだろう。3回以下なのか。\n5) 普通に二項分布として計算する。\nたかだかは例によってよく分からないので飛ばす。\n$$ $$\n6) たかだか問題によりパス。\n7) 1 1 - (( 3 / 4 ) ^ 10 + 10 * 3 ^ 9 / 4 ^ 10 + 45 * 3 ^ 8 / 4 ^ 10) [1] 0.4744072 0, 1, 2回生じる確率を二項分布の式から計算し、余事象の確率を計算する。\n0.4744\n8) 不良がの確率で存在する二項分布を考える。\n1 (898 / 1000)^10 [1] 0.3410071 1 10 * (102 / 1000) * (898 / 1000) ^ 9 [1] 0.3873354 1 45 * (102 / 1000) ^ 2 * (898 / 1000) ^ 8 [1] 0.197981 9) (a) 1 prod(7:10) / prod(1:4) * 2 ^6 / 3 ^ 10 [1] 0.2276076 (b) 1 prod(c(8, 9, 10)) / prod(1:3) * 8 / 3 ^ 10 + 9 * 10 / 2 * 4 / 3 ^ 10 + 10 / 3 ^ 10 [1] 0.01947535 10) 1 98 ^ 9 * 2 / 100 ^ 10 [1] 0.01667496 1 9 * 8 / 2 * 98 ^ 7 * 2 ^ 3 / 100 ^ 10 [1] 0.0002500202 11) ポワソン分布の式は以下。\nの時のを求めれば良い。\n1 exp(-0.1) [1] 0.9048374 これを二項分布で計算すると、\n1 (0.98) ^ 5 [1] 0.9039208 となり、おおよそ近い。\n12) 超幾何分布で考える。今気づいたけど、choose()関数でコンビネーション計算できるみたい。\n1 choose(60, 2) * choose(30, 2) / choose(90, 4) [1] 0.3013279 二項分布ならば以下。\n1 choose(4, 2) * (2 / 3) ^ 2 * (1 / 3) ^ 2 [1] 0.2962963 近からず遠からず。Nが少々少なかったか。\n13) 1 2 3 m = 100 * 0.02 x = 4 m ^ x * exp(-m) / factorial(x) [1] 0.09022352 14) 1 2 3 m = 200 * 0.03 x = 5 m ^ x * exp(-m) / factorial(x) [1] 0.1606231 15) 動物園の入場者数は4人と比べたら相当多いはず。そのため、ポアソン分布が使えると考える。\nポワソン分布の期待値はであり、それが4なのだから、確率の計算が可能。\n期待値の性質を使うというアイデアは一瞬分からなかったけど、とても便利な性質だなあ。\n1 2 3 m = 4 x = c(1, 2, 5) m ^ x * exp(-m) / factorial(x) [1] 0.07326256 0.14652511 0.15629345 16) 1 2 3 4 5 p = 1 / 10000 n = 20000 m = n * p m [1] 2 17) 1 2 3 4 n = 200 p = 0.02 4 ^ 2 * exp(-4) / factorial(2) [1] 0.1465251 18) 1 2 3 4 p = 0.012 n = 300 3.6 ^ 2 * exp(-3.6) / factorial(2) [1] 0.1770577 19) 一冊の本で、一ページあたりの誤植数の期待値が0.05であるポアソン分布を考える。\n1 2 x = c(0, 1, 2) 0.05 ^ x * exp(-0.05) / factorial(x) [1] 0.951229425 0.047561471 0.001189037 20) 1 4 ^ 1 * exp(-4) / factorial(1) [1] 0.07326256 例のごとく、たかだか問題は飛ばす。\n21) m = 5と指定されたポアソン分布。\n(a) 今更だけど、ポワソン分布の関数を作ろう。\n1 2 3 poisson_func \u0026lt;- function(m, x) { m ^ x * exp(-m) / factorial(x) } 1 poisson_func(5, 0) [1] 0.006737947 (b) 1 poisson_func(5, 2) [1] 0.08422434 (c) 1 poisson_func(5, 5) [1] 0.1754674 22) 1 1 - sum(poisson_func(4, c(0:5))) [1] 0.2148696 1 1 - sum(poisson_func(4, c(0:1))) [1] 0.9084218 ところで、これは確率密度関数がプロットしたらイメージわきやすい気がした。\n1 2 3 4 5 6 7 8 9 library(tidyverse) tibble( x = 1:20, p = poisson_func(4, 1:20) ) |\u0026gt; ggplot(aes(x = x, y = p)) + geom_point() + geom_line() 23) (a) 確率は単純にポワソン分布の式に代入すればよい。\n1 poisson_func(3, c(1:10)) [1] 0.1493612051 0.2240418077 0.2240418077 0.1680313557 0.1008188134 [6] 0.0504094067 0.0216040315 0.0081015118 0.0027005039 0.0008101512 平均値、すなわち期待値は確率に確率変数を乗算してから合計を計算すればよい。\n1 sum(poisson_func(3, 1:10) * 1:10) [1] 2.996693 確かに3に近い値となった。\n多分手計算の都合で10までとしているのだが、とても大きい値まで計算するとどうか。\n1 sum(poisson_func(3, 1:100) * 1:100) [1] 3 これ以上はオーバーフローしてしまうようだ。\n(b) 分散は二乗の期待値引く期待値の二乗で求める。\n1 sum(poisson_func(3, 1:10) * (1:10)^2) - sum(poisson_func(3, 1:10) * 1:10)^2 [1] 2.982299 これも大体3に近い。\n同じように大きい数字まで計算してみる。\n1 sum(poisson_func(3, 1:100) * (1:10)^2) - sum(poisson_func(3, 1:100) * 1:100)^2 [1] 2.963084 うーん　これが計算の限界か。コンピュータ上だと桁数の多い小数が計算できないというのは本当だったのか。\n24) 正規分布の確率密度関数でも、自作関数を作ってみよう。\n1 2 3 normal_function \u0026lt;- function(z) { exp(-z ^ 2 / 2) / sqrt(2 * pi) } 一応プロットして確認する。\n1 2 3 4 5 6 7 tibble( x = -1000:1000*0.01, p = normal_function(-1000:1000*0.01) ) |\u0026gt; ggplot(aes(x = x, y = p)) + geom_point() + geom_line() ちゃんと標準正規分布になっているようだ。いったんデータフレームにいれておく。\n積分値が欲しいが、この積分値を求めるのは結構しんどい。マクローリン展開しないといけない?\nと、調べてみるとRの標準関数でやる補法があるらしい。正規分布の密度(density)をintegral関数に与える。integral関数なんて・・・Rを五年以上やってて初めて聞いた・・・\n(a) 1 integrate(dnorm, -1, 1) 0.6826895 with absolute error \u0026lt; 7.6e-15 わーほんとに求まったすごい。\n(b)\u0026hellip;(f) 1 calc_normal_sum \u0026lt;- function(z) {integrate(dnorm, -z, z)} 1 2 c(2, 3, 1.96, 2.33, 2.58) |\u0026gt; map(\\(x) calc_normal_sum(x)) [[1]] 0.9544997 with absolute error \u0026lt; 1.8e-11 [[2]] 0.9973002 with absolute error \u0026lt; 9.3e-07 [[3]] 0.9500042 with absolute error \u0026lt; 1e-11 [[4]] 0.9801938 with absolute error \u0026lt; 1.2e-09 [[5]] 0.99012 with absolute error \u0026lt; 1.9e-08 25) 確率密度関数の積分値から確率を求める問題。\nRではqnorm()がそれを実現してくれる。\n1 qnorm(0.95, 0, 1) [1] 1.644854 ここで、0.95とは以下の部分の面積である。\n1 2 3 4 5 6 7 8 9 10 11 12 tibble( x = -1000:1000*0.01, p = normal_function(-1000:1000*0.01) ) -\u0026gt; df_norm df_norm |\u0026gt; ggplot(aes(x = x, y = p)) + geom_line() + geom_area( data = df_norm |\u0026gt; filter(x \u0026lt; 1.644854), aes(x = x, y = p) ) この点に注意して計算する。\n(a) 1 qnorm(0.45 + 0.5, 0, 1) [1] 1.644854 (b) 1 qnorm(0.96, 0, 1) [1] 1.750686 (c) 1 qnorm(0.07, 0, 1) [1] -1.475791 (d) 1 qnorm(0.65, 0, 1) [1] 0.3853205 (e) 1 qnorm(0.03, 0, 1) [1] -1.880794 (f) 1 qnorm(0.3 + 0.5, 0, 1) [1] 0.8416212 26) (a) integrate()関数を使えば確率密度関数の面積値を求めることが出来るが、標準正規分布でない場合は自作関数でwrapする必要があるのではないだろうか。\n1 2 dnorm_mod \u0026lt;- function(x) {dnorm(x = x, mean = 10, sd = 2)} integrate(dnorm_mod, -Inf, 13) 0.9331928 with absolute error \u0026lt; 1.5e-05 (b) 1 integrate(dnorm_mod, 6, Inf) 0.9772499 with absolute error \u0026lt; 1.1e-07 (c) 1 integrate(dnorm_mod, 6, 13) 0.9104427 with absolute error \u0026lt; 1.3e-13 27) 1 dnorm_mod \u0026lt;- function(x) {dnorm(x = x, mean = 57.4, sd = 8.4)} 1 integrate(dnorm_mod, -Inf, 70) 0.9331928 with absolute error \u0026lt; 1.5e-05 1 integrate(dnorm_mod, -Inf, 51.1) 0.2266274 with absolute error \u0026lt; 9e-05 1 integrate(dnorm_mod, 59.5, 76.3) 0.3890692 with absolute error \u0026lt; 4.3e-15 1 integrate(dnorm_mod, 44.8, 74.2) 0.9104427 with absolute error \u0026lt; 1.3e-13 1 integrate(dnorm_mod, 72.1, Inf) 0.04005916 with absolute error \u0026lt; 5.9e-07 1 integrate(dnorm_mod, 49, Inf) 0.8413447 with absolute error \u0026lt; 0.00011 28) 1 dnorm_mod \u0026lt;- function(x) {dnorm(x = x, mean = 71.8, sd = 5.6)} 1 1 - integrate(dnorm_mod, 78.8, Inf)[[1]] [1] 0.8943502 1 1 - integrate(dnorm_mod, -Inf, 60.6)[[1]] [1] 0.9772499 1 integrate(dnorm_mod, 74.6, 80.2) 0.2417303 with absolute error \u0026lt; 2.7e-15 1 integrate(dnorm_mod, 63.4, 80.2) 0.8663856 with absolute error \u0026lt; 9.6e-15 29) 1 dnorm_mod \u0026lt;- function(x) {dnorm(x = x, mean = 520, sd = 10)} 1 integrate(dnorm_mod, -Inf, 500) 0.02275013 with absolute error \u0026lt; 4.6e-05 30) 確率と平均値から正規分布の標準偏差を求める問題。\n参考ページと同じように解く。\nこの問題はRプログラミングで解くのは難しい。(多分)\n正規化する。\n標準正規分布表より、面積値が(0.5 - 0.2 = 0.3)となるようなところを探すとなので、\n31) 先ほどと似たような形で、を考える。\n1.28は確率面積値が0.4となる値を正規分布表から求めたもの。\n平均値は92.98となる。\n32) 1 2 dnorm_mod \u0026lt;- function(x) {dnorm(x, 60.5, 7.4)} integrate(dnorm_mod, 70, Inf)[[1]] * 100 [1] 9.960881 1 integrate(dnorm_mod, -Inf, 48)[[1]] * 100 [1] 4.559159 1 integrate(dnorm_mod, 56, 64)[[1]] * 100 [1] 41.03259 33) 正規分布において、面積値が0.9となる確率変数よりも多くの在庫を確保しておけばよい、と考える。\n1 qnorm(0.9, 250, 30) [1] 288.4465 289以上の在庫があればよい。\n34) 1 qnorm(0.95, 340, 26) [1] 382.7662 383個用意しておけばよい。\n35) (a) 1 integrate(\\(x) dnorm(x, 300, 35), 320, Inf) 0.2838546 with absolute error \u0026lt; 2.5e-05 28.4%\n(b) 1 integrate(\\(x) dnorm(x, 300, 35), 250, 350) 0.8468725 with absolute error \u0026lt; 9.4e-15 84.7%\n(c) 1 qnorm(0.75, 300, 35) [1] 323.6071 323.6時間\n36) (a) 1 integrate(\\(x) dnorm(x, 72.8, 15), 88, Inf) 0.1554505 with absolute error \u0026lt; 2.2e-06 (b) 1 1 - integrate(\\(x) dnorm(x, 72.8, 15), 32, Inf)[[1]] [1] 0.003264096 (c) 1 qnorm(0.88, 72.8, 15) [1] 90.4248 (d) 1 qnorm(0.25, 72.8, 15) [1] 62.68265 37) イメージするために、正規分布を図示してみる。\n1 2 3 4 5 6 7 8 9 10 library(tidyverse) tibble(x = 1:2000 * 0.1) |\u0026gt; mutate( dist_a = dnorm(x, 75, 15), dist_b = dnorm(x, 100, 10) ) |\u0026gt; pivot_longer(-1) |\u0026gt; ggplot(aes(x = x, y = value, col = name)) + geom_line() とは言っても、問題文をよく読むと二つの分布の関係性を気にする必要性は特になかった。\n1 integrate(\\(x) dnorm(x, 75, 15), 100, Inf) 0.04779035 with absolute error \u0026lt; 7.9e-05 1 integrate(\\(x) dnorm(x, 100, 10), -Inf, 75) 0.006209665 with absolute error \u0026lt; 2.3e-05 38) 1 2400 * integrate(\\(x) dnorm(x, 112, 12), 105, 125)[[1]] [1] 1394.005 回答と計算が少し違うが、おそらく正規分布表を使った事による誤差と思われる。\n39) 正規分布の平均・分散が以下で求められることを利用する。\n計算すると平均が80, 分散が8と分かる。\n1 integrate(\\(x) dnorm(x, 80, 8), 0.18 * 400, Inf) 0.8413447 with absolute error \u0026lt; 8.3e-05 40) 1 choose(14, 4) * (1 / 2) ^ 4 * (1 / 2) ^ 10 [1] 0.06109619 1 2 3 4 mu = 14 * (1 / 2) sigma = sqrt(mu * (1 / 2)) dnorm(4, mu, sigma) [1] 0.05895185 41) 1 2 3 4 mu = 60 sigma = sqrt(mu * (1 - 0.6)) integrate(\\(x) dnorm(x, mu, sigma), -Inf, 50) 0.02061341 with absolute error \u0026lt; 7.6e-05 42) 1 integrate(\\(x) dnorm(x, 1000 / 6, sqrt(1000 / 6 * 5 / 6)), 180, Inf) 0.1289495 with absolute error \u0026lt; 3.3e-09 1 integrate(\\(x) dnorm(x, 1000 / 6, sqrt(1000 / 6 * 5 / 6)), 140, 200) 0.9858353 with absolute error \u0026lt; 2.9e-09 1 # integrate(\\(x) dbinom(x, 1000, 1 / 6), 140, 200) dbinomはintegerしか引数にとれないらしい。integrateの計算がうまくいかなかった。\n43) やーっと練習問題も最後のページにたどり着いた。\n1 integrate(\\(x) dnorm(x, 0.36 * 400, sqrt(0.36 * 400 * (1 - 0.36))), 125, 400) 0.9761014 with absolute error \u0026lt; 3.3e-05 44) 1 integrate(\\(x) dnorm(x, 800*0.02, sqrt(800*0.02*0.98)), 20, Inf) 0.1562111 with absolute error \u0026lt; 4.7e-05 45) 1 integrate(\\(x) dnorm(x, 0.4 * 400, sqrt(400*0.4*0.6)), 180, Inf) 0.02061341 with absolute error \u0026lt; 7.7e-05 46) 1 integrate(\\(x) dnorm(x, 1000*0.1, sqrt(1000*0.1*0.9)), -Inf, 80) 0.01750749 with absolute error \u0026lt; 9.1e-05 47) 割愛(ネットにいくらでも解説落ちてるので)\n48) 割愛(ネットにいくらでも解説落ちてるので)\n49) 割愛(ネットにいくらでも解説落ちてるので)\n長かった。\n所感 実際的な問題文が多かったので、正規分布を実際の出来事にあてはめるとどうなるか、というイメージを身体で覚えた感じがする。\nにしても問題多かった・・。\n","date":"2022-10-23T00:00:00Z","permalink":"https://snitch0.github.io/p/basic-statistics-6/","title":"宮川公男「基礎統計学」第五版 第六章主な確率分布 練習問題の解法"},{"content":"完成形 info, warning, danger, normalを用意。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 {{% hint info %}} Info box. {{% /hint %}} {{% hint warning %}} Warning box. {{% /hint %}} {{% hint danger %}} Danger box. {{% /hint %}} {{% hint normal %}} Normal box. {{% /hint %}} Info box.P\nWarning box.\nDanger box.\nNormal box.\n作り方 全面的にNelis Oostens氏のコードをThe Unilicenseのもとで利用させていただいています。\nlayouts/shortcodes/hint.html Hugoのショートコードではどのテーマを利用しているかに関わらず、layouts/shortcodesがショートコードの定義ファイルの置き場であり、ファイル名(この場合はhint)がショートコード名になります。\nhint.html 1 2 3 4 {{ $type := .Get 0 }} {{ printf \u0026#34;\u0026lt;blockquote class=\\\u0026#34;md-hint %s\\\u0026#34;\u0026gt;\u0026#34; $type | htmlUnescape | safeHTML }} {{ .Inner | safeHTML }} {{ printf \u0026#34;\u0026lt;/blockquote\u0026gt;\u0026#34; | htmlUnescape | safeHTML }} theme/**/assets/scss/custom.scss scssにてcssを定義します。記述すべき場所はテーマによって違うと思います。 私が使用しているStack themeではtheme/hugo-theme-stack/assets/scss/custom.scssです。\n冒頭紹介した参考記事では、カラーコードをどこかの変数から取ってきているようですが、参照すべきその変数が記事内には書かれていなかったのでハードコードしました。 Windows PowerToysのカラーピッカーを使用してちまちまとカラーピック。\ncustom.scss 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 .md-hint { \u0026amp;.info { border-left-color: rgba(102, 187, 255, 1); background-color: rgba(102, 187, 255, 0.25); } \u0026amp;.warning { border-left-color: rgba(255, 221, 102, 1); background-color: rgba(255, 221, 102, 0.25); } \u0026amp;.danger { border-left-color: rgba(255, 102, 102, 1); background-color: rgba(255, 102, 102, 0.25); } \u0026amp;.normal { border-left-color: rgba(91, 93, 94, 1); background-color: rgba(91, 93, 94, 0.05); } } あとは使うだけ! 以下のようにして使います。\n1 2 3 {{% hint info %}} Info box. {{% /hint %}} HugoではGo言語がバックエンドなので、ショートコードの作り方はややGoっぽい特殊な書き方です。 ただまあ･･･PHPよりは簡単なのかな。\n","date":"2022-10-14T00:00:00Z","permalink":"https://snitch0.github.io/p/creating-hugo-shortcode/","title":"Hugoのショートコードを作る"},{"content":"この記事について しばらく前に会社の計算サーバーでVSCode×conda×rmd/qmdの環境を試行錯誤して構築することができた。\n作っただけで満足してしまってその後はjupyter notebookしか使わないという暴挙にでてしまっていたが、これからはquarto活用を推進していこうという気になったので、改めて環境を見直した。\nこの記事を読んでできるようになること VSCode-R(REditorSupport)を介してrmd/qmdのチャンクをインタラクティブモードで実行する際、指定したconda環境を使うようになります。 また、ターミナルにはradianが使用されるようになります。 誰向けか Rのバージョンを使い分けたい人 Rのバージョン管理にcondaを使っている人 わけあってRのアップデートを気軽にはできない場合1 方法 クレジット 最初に、この解決法を知るに至った、神的なGitHub issueをクレジットしておきたい。\n自分はこちらのイシュー(Rとradianをconda環境指定しつつvscode-Rで使うにはどうしたら良いか)についていたelsherbiniさんのスクリプトで成功した。\n最小構成のconda環境 まず環境を作る。これさえあればとりあえずはvscodeでの解析環境が作れる。\n1 2 3 4 mamba create -n r42 \u0026#34;r-base==4.2\u0026#34; # 完了後 mamba activate r42 mamba install radian radianを使う気が無いなら省略してもOK。\nもしjupyter Notebook環境も作りたいなら、以下のものも用意しておく。\n1 mamba install r-irkernel jupyterlab conda-forgeレポジトリにはRパッケージも存在しており、コマンドライン上でパッケージをインストールすることは可能だ。\nしかし、この後インストールが必須なlanguageserverをcondaでインストールしてしまうと、依存関係の設定ミスにより強制的にR4.1にダウングレードされてしまうので注意が必要だ。 基本的にRのパッケージはR内でインストールする方が良さそうだ。\n1 radian 1 2 3 4 R version 4.2.1 (2022-06-23) -- \u0026#34;Funny-Looking Kid\u0026#34; Platform: x86_64-pc-linux-gnu (64-bit) R\u0026gt; install.packages(\u0026#34;languageserver\u0026#34;) 最低限必要なパッケージはこのlanguageserverパッケージだけ。\n起動用シェルスクリプトを作成 Windowsだとps1ファイルか何かを使うのだと思うが、Linux/Mac環境しか試してないので不明。\n以下の内容を適当な場所へ保存。ファイル名は何でも良い。\n$HOME/.config/R/vscode-r-conda.sh 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #!/bin/bash # conda環境名はここで指定する R_ENV=r42 \\_\\_conda_setup=\u0026#34;![(\\\u0026#39;](https://latex.codecogs.com/svg.latex?%28%27 \u0026#34;(\u0026#39;\u0026#34;)HOME/mambaforge/bin/conda\u0026#39; \u0026#39;shell.zsh\u0026#39; \u0026#39;hook\u0026#39; 2\\\u0026gt; /dev/null)\u0026#34; if \\[ ![? -eq 0 \\]; then eval \\\u0026#34;](https://latex.codecogs.com/svg.latex?%3F%20-eq%200%20%5D%3B%20then%20%20eval%20%22 \u0026#34;? -eq 0 ]; then eval \u0026#34;\u0026#34;)\\_\\_conda_setup\u0026#34; else if \\[ -f \u0026#34;![HOME/mambaforge/etc/profile.d/conda.sh\\\u0026#34; \\]; then . \\\u0026#34;](https://latex.codecogs.com/svg.latex?HOME%2Fmambaforge%2Fetc%2Fprofile.d%2Fconda.sh%22%20%5D%3B%20then%20%20.%20%22 \u0026#34;HOME/mambaforge/etc/profile.d/conda.sh\u0026#34; ]; then . \u0026#34;\u0026#34;)HOME/mambaforge/etc/profile.d/conda.sh\u0026#34; else export PATH=\u0026#34;![HOME/mambaforge/bin:](https://latex.codecogs.com/svg.latex?HOME%2Fmambaforge%2Fbin%3A \u0026#34;HOME/mambaforge/bin:\u0026#34;)PATH\u0026#34; fi fi unset \\_\\_conda_setup if \\[ -f \u0026#34;![HOME/mambaforge/etc/profile.d/mamba.sh\\\u0026#34; \\]; then . \\\u0026#34;](https://latex.codecogs.com/svg.latex?HOME%2Fmambaforge%2Fetc%2Fprofile.d%2Fmamba.sh%22%20%5D%3B%20then%20%20.%20%22 \u0026#34;HOME/mambaforge/etc/profile.d/mamba.sh\u0026#34; ]; then . \u0026#34;\u0026#34;)HOME/mambaforge/etc/profile.d/mamba.sh\u0026#34; fi mamba deactivate \u0026amp;\u0026amp; mamba activate \\$R_ENV radian 一応実行可能になってるか確認する。\n1 2 chmod +x /home/snitch/.config/R/vscode-r-conda.sh /home/snitch/.config/R/vscode-r-conda.sh 正常にconda環境のRがradianで立ち上がればOK。\nVSCodeに登録 最後にVSCodeの登録をする。\n作業完了、実行確認 ここまでやれば、conda環境がVSCodeの実行環境になったはず。このqmdファイルで実行できるか試してみる。\n1 plot(iris) バッチリ✴️\nもしもバージョン変更をしたくなったら、conda環境を作り直してからシェルスクリプトの仮想環境名を変更するだけで良いので、超簡単。\n自分の場合は数十人で使っている共有サーバーなので二三年に一度しかアプデできないし、LinuxのOS的な問題でRバージョンを上げられないという悲しい状況です。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2022-09-22T00:00:00Z","permalink":"https://snitch0.github.io/p/r-vscode-conda/","title":"VSCodeでconda環境のRをradianとともに使う"},{"content":"LinterとFormatterにも色々あることを知る 先日Twitterを徘徊していたら、ruffというrust製のpython linterのレポジトリを発見した。試しに使ってみたら本当に爆速で驚き😲\nで、自分はVSCodeユーザーなので、どうやったらVSCodeのlinterとしてruffを使えるのだろうと思ったら現時点では対応してないみたいだった。詳しいことはよく分からないが、どうやらVSCodeのpython拡張側での対応が必要らしく、少なくともVSCode python拡張のメンテナが実装することはないらしい。\n残念だなぁと思ったが、実際VSCode公式のpylint以外の選択肢についてあんまり知らなかったので調べてみることに。\n現在サポートされているlinter Command palletteから「Python: リンターを選択」を実行したとき、bandit、flake8、mypy、prospector、pycodestyle、pydocstyle、py lama、pylintの8つが選択可能だった。\n違いは以下の記事がとても参考になった。\nlinter flake8 + mypy が自分的には必須かなと思った。\nflake8はざっと見た感じ、コーディング規約を必要十分な感じに網羅していると思った。 mypyは型チェックするのに必須。\nでもせっかく調べたので、banditも入れてみた。セキュリティを気をつけ無きゃいけない機会は仕事上ほとんどないけど。\nformatter 現状あまり選択肢があるわけではないが、blackが割と厳しめでよさそう。\n使ってみたら一行あたりの文字数制限がblackとflake8で食い違ってしまったので、flake8の実行オプションを設定してやる必要があるのと、エディタの縦線の位置をずらしてあげる。\n1 2 3 4 5 6 { \u0026#34;python.linting.flake8Enabled\u0026#34;: true, \u0026#34;python.linting.flake8Args\u0026#34;: [ \u0026#34;--max-line-length\u0026#34;, \u0026#34;88\u0026#34;, \u0026#34;--ignore=E203,W503,W504\u0026#34; ], } コレに関しては以下の記事を参考にさせていただいた。\n完成品 結局あれこれいじってこうなった。\nWSL2の設定ファイルなのでスリムだが、気づけばpython系とneovim系ぐらいしか設定してないのか。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 { \u0026#34;python.linting.flake8Enabled\u0026#34;: true, \u0026#34;python.linting.flake8Args\u0026#34;: [ \u0026#34;--max-line-length\u0026#34;, \u0026#34;88\u0026#34;, \u0026#34;--ignore=E203,W503,W504\u0026#34; ], \u0026#34;python.linting.mypyEnabled\u0026#34;: true, \u0026#34;python.languageServer\u0026#34;: \u0026#34;Pylance\u0026#34;, \u0026#34;python.analysis.completeFunctionParens\u0026#34;: true, \u0026#34;python.analysis.logLevel\u0026#34;: \u0026#34;Warning\u0026#34;, \u0026#34;python.linting.banditEnabled\u0026#34;: true, \u0026#34;python.testing.pytestEnabled\u0026#34;: true, \u0026#34;[python]\u0026#34;: { \u0026#34;editor.defaultFormatter\u0026#34;: null, \u0026#34;editor.formatOnSave\u0026#34;: true }, \u0026#34;python.formatting.provider\u0026#34;: \u0026#34;black\u0026#34;, \u0026#34;python.analysis.typeCheckingMode\u0026#34;: \u0026#34;basic\u0026#34;, \u0026#34;vscode-neovim.mouseSelectionStartVisualMode\u0026#34;: false, \u0026#34;vscode-neovim.neovimInitVimPaths.linux\u0026#34;: \u0026#34;~/.config/nvim/init.lua\u0026#34;, \u0026#34;editor.lineNumbers\u0026#34;: \u0026#34;relative\u0026#34;, } ","date":"2022-09-21T00:00:00Z","permalink":"https://snitch0.github.io/p/python-linter-formatter/","title":"Pythonのlinterとformatter事情(@VisualStudioCode)"},{"content":"書籍 データ分析のための数理モデル入門　本質をとらえた分析のために[ 江崎貴裕 ] リンク\n⭐⭐⭐⭐(星4)\nソシム社のデータ分析シリーズの一冊目。めちゃくちゃTwitter上で評判が良かったので気にはなっていたが、youtubeでとても勉強させてもらっているアイシア・ソリッドさん(のマスター)がシリーズ4冊目をこの頃出版されたということなので、Kindleセールにてまとめ買いをした。 めっちゃわかりやすい説明をしてくれるアイシアさんがシリーズ全作オススメされているので、きっと参考になるだろうと思いつつ、Amazonレビューもそれなりに高く、読む前の期待値としては高め。\n結論から言うと、データ分析に少なからず関わる機会がある初学者にはとてもお勧め。よく使う統計手法には慣れている中級者以上でも、視野を広げたいのならとてもお勧め。 数式的な理解がないと満足出来ない人にはお勧めできない。なぜなら本書では数式が全くといって良いほど出てこないから。\nタイトル通り本書は数式モデルについて解説しているが、多項式モデルや一般線形モデルに限らず、統計モデルや確率モデルにもしっかり触れられており、最後には時系列モデルや機械学習モデルにも触れられている。難解な数式はほとんど無く、メリットデメリットが例示付きでとにかく浅く広く解説されている。\n私的には聞いたことはあるけど使ったこと無いモデルとか、まるで聞いたことないモデルまで、様々なモデルの存在を知ることができ、本当に買って良かったと思う。\n星5にならなかった理由だが、これはおそらく自分の性格の問題だ。本当に全てが浅く紹介されているだけなので、それぞれのモデルについて深く知りたいなら別の参考書をあたる必要がある。その「なんとなく分かった気になっておいて、とりあえず前に進む」というのが最初のうちはなかなか出来なかったので、全然読み進められなかった。。 しかし、適宜たくさんの参考書が筆者により紹介されているし、たしかに一部の参考書を引いてみるととても分かりやすかった。\nこの一冊で数理モデルを扱えるようになるわけでは無いが、この一冊から入門し、全体を俯瞰したのちに細かい分野を別の参考書で補う勉強スタイルが非常に効率的かも。\n分析者のためのデータ解釈学入門　データの本質をとらえる技術[ 江崎貴裕 ] ⭐⭐⭐⭐⭐(星5)\nリンク\nこれも前述と同じ江崎先生による書籍で、ソシムデータ分析シリーズの二作目。\n正直この本は傑作級に素晴らしい。これまでに読んだ1どの統計書よりも分かりやすく、かつ網羅的に「統計学を使う上での注意点」が網羅されている。仮説検定法に潜む問題や機械学習における過学習の問題など有名どころはもちろん、サンプルサイズと効果量の話とか、様々なバイアスの話とか、、、学生の時に習った(であろう)重要ポイントがくまなく言及されている。\n会社の人たちに「黙ってこれ読んでから質問してくれ」と言いたいレベルで、本書の内容はデータ分析に携わる人なら必ず知っておくべき内容ばかりが詰まってる。\n「数理モデル」と同様、本書にも数式はほぼ登場しないが、前書よりも一つ一つのイシューに対する説明がより丁寧になっている。「数理モデル」は一通りサーっと読み通してから、引っかかる部分があれば追加で勉強、というスタイルだが、本書はこの一冊をとにかくじっくり熟読すれば様々なバイアスの存在・問題点を学ぶことが出来る。\nニーチェが京都にやってきて17歳の私に哲学のこと教えてくれた。[ 原田まりる ] リンク\n⭐⭐⭐(星3)\nこれは期待してなかったけど、意外になかなか面白かった本。\nKindleのまとめ買いセール[^2]の数合わせで購入。「若者ウケを狙った寒いなりきりラノベかなぁ\u0026hellip;」と思いきやちょっと違った。\nストーリーはこうだ。失恋をした女子高生のもとへ転生したニーチェがやってきて、「祝福できないくらいならいっそ呪ってしまえ」と言いながら彼女に哲学を説く。\nその後キルケゴールやサルトルといった歴史上の哲学者もニーチェと同じように転生者として登場し、それぞれの哲学を彼女に説く。様々な哲学の考え方を知るに従い、失恋や自身の親との関係などで抱えていたもやもやしたものに気持ちの区切りを付けることができるようになり、成長していくという話。\nはじめはなろう系の異世界転生のような月並みのストーリーとして読んでいたのだが、読み始めてすぐその間違いに気がつく。この本は小説として読むのではなく、会話形式でそれぞれの哲学者の考えを子供にも分かるように説明した極めて平易な哲学書と解釈するのが正しいのだ。そう考えると極めて読みやすく、分かりやすい。というか哲学書はこうやって説明してくれればいいんだ、とはっとした。\nAmazonレビューは星4.5と比較的高いが、皆ストーリーを面白いと言っているわけではないので私と同じ感想なんだと思う。\n「子供にも分かるように」とは言ったが、正直高校生には難しいかも。人生経験的に共感できるポイントが少なそう。社会人なら共感ポイントが多く、むしろ救われる気持ちにすらなるかもしれないと思う。\nガジェット 実は自分、結構ガジェット好きです。結構ガジェット系youtuberの動画をずっと見ちゃう。\nKeychron K2 non-backlight red リンク\n🌟🌟🌟(星3兆個)\nKeychronは香港のメーカーで、アメリカのキーボード大好きyoutuberにも人気があるらしい。\nきっかけはtakuyaさんのNeovim動画で、むっちゃかっけぇと思ったとき。\n調べてみたら100ドルを切る値段でありながら、HHKBなどの超高級キーボード並に打鍵感が良いらしいとのこと。\nkeychronというメーカーを調べてみると、主にキー数の違いによって様々なバージョンのキーボードがあるらしい。詳しい違いについてはやまかふぇさんの動画が詳しい。 見比べた中では最初に見たkeychron \u0026ldquo;K2\u0026quot;が一番良く、カーソルキーやInsキーがうまいこと収まっているところに惚れた。 通常版でも良かったが、別にキーボードが光る必要は無いと思ってる人なのでnon-backlightにした。\n意外とネット通販でも通常価格で販売されていて、在庫さえあればどこでも買えそう。しかし、謎のkyochron.jpという公式っぽいサイトを見つけたので、ここで買ってみた。\nこのサイトで購入した人がほぼ見当たらず、しかも謎に通常販売価格より1000円以上安く(自分が購入したときは9300円、現在は10400円)、発送も香港からということで不安しかなかった。 怖かったのでPaypalで購入し、メールアドレスも捨てアドで登録。6-9日くらいは到着に要すると書いてあったが10日立っても届かず、不安しかなかった(チャットサポートも不通)。 が、結局11日目で佐川急便到着。疑ってすまなかった。。\n感想は最高。打鍵感が本当に気持ちいい。高級キーボードの「スコスコ感」ってこれかぁ。\nHHKBなら最低でも3万円くらいは積まないといけないが、keychronは1万円で入門できて非常にお手軽。おすすめ。\nなお気に入りすぎて純正パームレストも購入した。(これは楽天スーパーセール時にヤマダだかコジマだかのショップにて購入)\nhttps://t.co/7pes6LbZAF なるサイトがhttps://t.co/e2x0hPlcSj や店頭価格よりも安いもんだから詐欺サイトかと疑ってしまいましたが、ちゃんと届きました😇\nkeychron K2 … うっとりする美しさ… pic.twitter.com/YMe5xVnMVK\n\u0026mdash; スニッチ (@excel2rlang) September 10, 2022 ぶっちゃけ統計学勉強中なので5冊も読んでないけど･･･\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2022-09-19T00:00:00Z","permalink":"https://snitch0.github.io/p/items-22-09/","title":"最近買ったもの(2022-9月)"},{"content":"pythonライブラリの使い方が分からなくなることがある pythonライブラリにはド定番のライブラリがいくつもあるが、それらの仕様は結構忘れがち。\nたとえばcsvのDictWriterクラス。引数がファイルオブジェクトなのかそれともパスを文字列で与えるのか、刹那の思考をはさんだ後にwith open()などと書き始める。\ncsv.DictWriterクラスならまだ良いが、やり方が複数通り存在する場合になるともうカオスだ。urllib.requestとrequestsのどっち使うんだとか、はたまたurllib3はなんなんだとか。。そんな「結局何が正解なん」案件でsubprocessの使い方についてちょっと思うところがあった。\nsubprocessライブラリの使い方 色々やりたいときはPopenクラスを使う、簡単なユーズケースならrunメソッドを使う、という認識でいたので、基本的に何も考えずPopenクラスを毎回使っていた。\nこんな感じ。\n1 2 3 4 from subprocess import Popen ps = Popen([\u0026#39;ls\u0026#39;, \u0026#39;-lah\u0026#39;]) ps.wait() Popen.wait()するタイミングをずらすことで非同期処理的にマルチプロセス化することもあるため、個人的にはシェルスクリプトとしてpythonを使う際には欠かせないやつ🤔\nstdoutを使おうとするとちょい面倒 標準出力を取得しようとするとsubprocess.PIPEが必要になるのでちょいめんどくさい。バイト文字列で選ってくるところがなおさら😅\n1 2 3 4 5 from subprocess import Popen, PIPE ps = Popen([\u0026#39;echo\u0026#39;, \u0026#39;hello\u0026#39;], stdout=PIPE) s_out = ps.stdout.readlines() print([s.decode(\u0026#34;utf-8\u0026#34;) for s in s_out]) ['hello\\n'] ググったらsubprocess.runの方が楽らしいと知る こちらのQiita記事を拝読すると、「suborocess.runを使うのが良いとされている」とか「capture_outputを使ってもできる」というのを聞いて👀から🐟!\n1 2 3 4 5 import subprocess ps = subprocess.run([\u0026#39;echo\u0026#39;, \u0026#39;hello\u0026#39;], capture_output=True, text=True) s_out = ps.stdout print(s_out) hello \u0026ndash;はぁ･･･勉強不足でした。。すみません。。と思いつつdocumentを見ると確かに以下のようにrunメソッドが推奨されていた。1\nサブプロセスを起動するために推奨される方法は、すべての用法を扱える run() 関数を使用することです。より高度な用法では下層の Popen インターフェースを直接使用することもできます。\nまた、capture_outputオプションはpython3.7で実装されたらしい。なるほど比較的新しいけど、少なくともセキュリティサポートされているバージョンをきちんと追ってる人なら間違えてはいけないポイントだろう。\nみんなちゃんと情報フォローしてるのか?と気になって調べてみた 結論、Qiita記事はちょっと危険だなと思った。自分も似たようなものだが･･･\nやばいパターン①推奨されていない書き方を解説している shell=Trueを使えば簡単にパイプが使えるので、便利なことは便利。しかし、任意のコードを実行させられる可能性があるので、ウェブフレームワークなどで使うのは御法度というのが有名。 これを説明せずに「shell=Trueの方が初心者にはオススメ」などと平然と書かれているケースがあった。\nちょっと気になったパターン②capture_outputオプションの言及がない 先に言っておくが、個人ブログは高確率でこれに言及している。最初の投稿時に言及が無くとも、ほぼ全員が追記していた。すごい😲きっと多分自分のコンテンツに責任を持っているのだろう。自分もそうならねば。\nPopen.PIPEの方法はQiita記事だけをみていたらゴールドスタンダードに見えるだろう。現に自分がそうだった。\nやっぱ、公式ドキュメントはちゃんと読んだ方が良いわ 正直自分はpythonドキュメントきちんと読んでこなかった。だってフォントとかレイアウトとかのせいか、読みにくいんだもん。\nしかし、細かい推奨レベルや後で追加されたオプションなど、知らないと恥かく内容も多いと感じた。\nコツコツpythonドキュメントをちゃんと読み直してみるのもいい学習方法かもしれない。\nこれを推奨ととるかは読解力次第な気もする\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2022-09-12T00:00:00Z","permalink":"https://snitch0.github.io/p/python-subprocess/","title":"subprocessライブラリの使い方って結局何が正解なん"},{"content":"Headings 一般的なmarkdownと同様、\u0026lt;h1\u0026gt;-\u0026lt;h6\u0026gt;タグに変換される。\nh1 h2 h3 h4 h5 h6 Paragraph Sudden looked elinor off gay estate nor silent. Son read such next see the rest two. Was use extent old entire sussex. Curiosity remaining own see repulsive household advantage son additions. Supposing exquisite daughters eagerness why repulsive for. Praise turned it lovers be warmly by. Little do it eldest former be if.\nRandom TextGenerator\n私は多年どうしても同じ存在めとして事の時の当てるなう。よし次第が納得めはよほど大きな失敗たたかもがさてならたがも経過いうたましょから、全くにも思わたたないたら。本領をいうですのももっとも前に何だかだませう。いったい嘉納さんを標榜書生ますます推察をすみた一口いわゆる主義何か活動にというお仕事たましででしょたって、いわゆる十月はそれかがた学校よりしで、岡田さんの訳が人の私がやはりお入会と致さけれども私肴がご講演としようについに不反対がつけですでて、ちっとも正しく意味をいううてならまいので掘りでで。つまりそうしてご鶴嘴を待っ気もたった公平ときまったて、そのらとはありありからという時分より云っばいますう。\nすぐ使えるダミーテキスト\nBack quote Backquotesはquartoの特性というよりは、hugoのテーマ次第なところが大きい。\nBackquote without attribution Be yourself;everyone else is already taken. ― Oscar Wilde\nBackquote with attribution Two things are infinite: the universe and human stupidity; and I\u0026rsquo;m not sure about the universe.\nAlbert Einstein1\nTables Col1 Col2 Tom 24 Clara 34 Italics Bold Code italics bold code Code block quartoの実行結果がネイティブに動くのは素晴らしいなあ。\ncodeタグのcssは改良の余地がありそう。\nMarkdown simple code block 1 2 3 4 5 library(dplyr) mtcars |\u0026gt; group_by(cyl) |\u0026gt; summarise(mean(mpg)) Hugo hilighting shortcode Hugoのショートコードはquartoのレンダリング時に若干崩壊するようだ。\n1 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \\\u0026lt;!doctype html\\\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt; Example HTML5 Document \u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt; Test \u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Quarto code chunk 1 library(dplyr) 次のパッケージを付け加えます: 'dplyr' 以下のオブジェクトは 'package:stats' からマスクされています: filter, lag 以下のオブジェクトは 'package:base' からマスクされています: intersect, setdiff, setequal, union 1 2 3 4 mtcars |\u0026gt; group_by(cyl) |\u0026gt; summarise(mean(mpg)) # A tibble: 3 × 2 cyl `mean(mpg)` \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; 1 4 26.7 2 6 19.7 3 8 15.1 Quarto code chunk with plot 1 2 3 4 5 pacman::p_load(ggplot2) mtcars |\u0026gt; ggplot(aes(x = mpg, y = hp, col = cyl)) + geom_point() 1 2 3 4 5 6 7 8 9 10 import seaborn.objects as so from palmerpenguins import load_penguins penguins = load_penguins() ( so.Plot(penguins, x=\u0026#34;bill_length_mm\u0026#34;, y=\u0026#34;bill_depth_mm\u0026#34;) .add(so.Dot()) .show() ) Diff 1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese Other Elements \u0026mdash; abbr, sub, sup, kbd, mark 1 2 3 4 5 6 7 8 9 \u0026lt;abbr title=\u0026#34;Graphics Interchange Format\u0026#34;\u0026gt;GIF\u0026lt;/abbr\u0026gt; is a bitmap image format. H\u0026lt;sub\u0026gt;2\u0026lt;/sub\u0026gt;O X\u0026lt;sup\u0026gt;n\u0026lt;/sup\u0026gt; + Y\u0026lt;sup\u0026gt;n\u0026lt;/sup\u0026gt; = Z\u0026lt;sup\u0026gt;n\u0026lt;/sup\u0026gt; Press \u0026lt;kbd\u0026gt;\u0026lt;kbd\u0026gt;CTRL\u0026lt;/kbd\u0026gt;+\u0026lt;kbd\u0026gt;ALT\u0026lt;/kbd\u0026gt;+\u0026lt;kbd\u0026gt;Delete\u0026lt;/kbd\u0026gt;\u0026lt;/kbd\u0026gt; to end the session. Most \u0026lt;mark\u0026gt;salamanders\u0026lt;/mark\u0026gt; are nocturnal, and hunt for insects, worms, and other small creatures. GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nHyperlinked image Google\nRich-content Shortcodeにdouble-quotationが含まれていると、rendering時にsmart-quoteに変換されてしまう仕様らしい。 これはシンタックスエラーの引き金となってhugoがレンダリングに失敗してしまうので、現状主導でmarkdownファイルを修正してやる必要がある。Issueあげようかと思ったら既に修正に取り組んでくれているみたいだった。今後に期待。\nQuote Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n― A famous person, The book they wrote youtube アルバート・アインシュタイン\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2022-09-11T00:00:00Z","permalink":"https://snitch0.github.io/p/blog-syntax/","title":"Quarto(とHugo)のSyntax"},{"content":"QuartoにおけるPythonの仕様 Quartoは以下のようにRでもPythonでも一つのファイルでレンダリングできるのが素晴らしい✨\nしかし、Python単独なら特に難しいことは無いが、RとPythonが共存するとある問題が生じる。\n1 2 result = lm(data = iris, Sepal.Width ~ Sepal.Length) summary(result) Call: lm(formula = Sepal.Width ~ Sepal.Length, data = iris) Residuals: Min 1Q Median 3Q Max -1.1095 -0.2454 -0.0167 0.2763 1.3338 Coefficients: Estimate Std. Error t value Pr(\u0026gt;|t|) (Intercept) 3.41895 0.25356 13.48 \u0026lt;2e-16 *** Sepal.Length -0.06188 0.04297 -1.44 0.152 --- Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 Residual standard error: 0.4343 on 148 degrees of freedom Multiple R-squared: 0.01382, Adjusted R-squared: 0.007159 F-statistic: 2.074 on 1 and 148 DF, p-value: 0.1519 1 2 3 4 5 6 7 8 9 10 11 12 from sklearn.datasets import load_iris from sklearn import linear_model import pandas as pd iris = load_iris() df = pd.DataFrame(iris.data, columns = [\u0026#39;SepalLength\u0026#39;, \u0026#39;SepalWidth\u0026#39;, \u0026#39;PetalLength\u0026#39;, \u0026#39;PetalWidth\u0026#39;]) df[\u0026#34;Name\u0026#34;] = pd.Series(iris.target) model = linear_model.LinearRegression() ft = model.fit(df[[\u0026#34;SepalLength\u0026#34;]], df[[\u0026#34;SepalWidth\u0026#34;]]) print(f\u0026#34;Intercept: {ft.intercept_[0]:.6}, Coef: {ft.coef_[0][0]:.6}\u0026#34;) Intercept: 3.41895, Coef: -0.0618848 エンジンにjupyterを使う場合 Pythonを使うなら、おそらくこれが一番明快でおすすめの方法になる。\nqmdのyamlヘッダにてengine: jupyterを選択しておく方法。たとえば、以下のようにする。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 title: \u0026#34;QuartoでPythonを使うときの注意とか\u0026#34; description: 意外と複雑な仕様?😈 author: Snitch date: \u0026#34;2022-09-11\u0026#34; categories: - Quarto - R - Python - Reticulate - Linux tags: - quarto - R - Python format: hugo slug: \u0026#34;python-and-quarto\u0026#34; jupyter: python3 html-math-method: webtex 一部はhugo関係のものもあるが、jupyterやhtml-math-method の部分はquartoに由来する。(いずれこのヘッダオプションも研究しなければ・・・)\n要はjupyterのpython3カーネルを使っているというだけなので、bashカーネルだってRカーネルだって存在さえしてれば使えるということなのだろう。\nこのオプションを指定している間に起こる諸問題1はjupyter由来のものになると思われるので、対処はしやすそう。しかしipywidgetなどはhugoへのレンダリングは厳しそう。qmdではなくipynbからやる方が無難だろう。\nしかし、このjupyterカーネルでは単一のカーネルしか指定できないので、RとPythonの共存は不可能である･･･。\nエンジンにjupyterを使用しない場合 jupyterを指定しない場合はpythonセルがreticulate+knitr経由で実行される。PythonとR両方を使ったドキュメントを気軽に書くことが出来るのはreticulate様のおかげだったのだ。万歳。\nしかし、reticulateは親切なんだかお節介なんだか分からないが、python実行バイナリのパス指定方法が複数あるせいで設定変更が一発で効かないことがしばしばあり、個人的にそれがreticulateを使う気にならない理由の一つ🐍2\nそして、reticulateの設定で見事にハマった。\n備忘録も兼ねてこのハマりポイント2つを残しておきたいと思う。\nreticulateのハマりポイント 仮想環境には気をつける 自分は普段pyenvとmambaforgeの二つを主なpythonソースとして使っている。前者は汎用的なコーディング(シェルスクリプト作成など)用で、後者はガッツリバイオインフォ解析する時用で使い分けている。\n今回何も考えずに実行しようとしたら、pyenvがうまく認識されてくれなかった。\n調べてみたところ、shared libraryを作らないpyenvはそれを必須とするreticulateと相性が悪いらしい。このページに書かれた手順を試してはみたが、やはり同じエラーが出るだけだった。\n諦めてmambaforgeに専用の仮想環境を用意してやったところ、うまく動作した。\n1 mamba create -n pyr python=3.10 RETICULATE_PYTHON環境変数に注意する 要はこの変数に適切なパスが通っていれば問題ないが、環境変数であるせいか、セッションステータスによっては反映されたりされなかったりするのが面倒だった。\nネットを見ると色々と対処方法が書いてあり、use_conda()を使うだとか、use_python()を使うとかの情報があるが、``./Renviron`に変数を記入してやるのが一番問題が起きにくかった。根拠が曖昧な経験則でアレだが、reticulateはこういう「なんでうまく行ったのがが分からない」ケースがちょいちょいある。\n.Renviron 1 RETICULATE_PYTHON=\u0026#34;~/mambaforge/envs/pyr/bin/python\u0026#34; 他にも.RprofileにSys.setenv(RETICULATE_PYTHON=)などと定義してやる方法もあるらしいが、なんとなくOS側で定義されていた方が安心な気がする。\nmatplotlibのplot inlineとか。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nならRstudio使いなさいよみたいな声が聞こえてきそうだが、Rstudioでpythonコーディングは結構キツい。pythonコーディングはVSCodeやPyCharmの方が圧倒的に優れており、めいっぱいPython書く人ならこれに同意してくれると思う。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2022-09-11T00:00:00Z","permalink":"https://snitch0.github.io/p/python-and-quarto/","title":"QuartoでPythonを使うときの注意とか"},{"content":"動機 私はexcel2rlang.comというRプログラミング解説ブログを管理しているヒトです。猫の名前をお借りして、スニッチという名前でやっています🐈‍⬛\nメインブログではR関連でまとまった内容を時間をかけて推敲しながら作っていく方針だったのですが、Rとは関係の無い話や、ライトな話題を吐き出しにくいことや、Wordpressとphpというフレームワークが気に入らないことなどの不満を常に抱えていました。\nあと、二ヶ月位前に「スニッチさんのブログ、読み込み遅いですね」と言われてピキったのもモチベの一つですね\u0026hellip;😓\nそんな折、quartoがアツいぞという話をあっちこっちで聞くようになってきて、このトレンドには乗っておこうかなという軽い気持ちでquartoを使ったブログを作ってみることにしました。\nHugo and Quarto Quartoのdocumentationをよくよく読んだらHugoへのレンダリングが可能ということだったので、Hugoでブログを作ってみることにしました。\n調べてみたところ、{blogdown}パッケージを通じてhugoのレンダリングの持ち込む方法をとっている人は見かけるものの、Hugo themeを選ばずにquartoを使ったブログの作り方を解説している人は見つかりませんでした。\nこのブログでのquartoブログの作り方解説が誰かのためになれば嬉しいし、まとまった内容になったらメインブログの方に再編してアップしても良いかなと思います。\nこれからいっぱい書くぞー って最初は誰でも意気込みますが、軽い内容のエントリを量産していこうと思います🖐️\n","date":"2022-09-10T00:00:00Z","permalink":"https://snitch0.github.io/p/first-post/","title":"Quartoを使った2ndブログを作ってみた"}]