<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>deepl on バイオベンチャーBIのtech blog</title>
        <link>https://snitch0.github.io/tags/deepl/</link>
        <description>Recent content in deepl on バイオベンチャーBIのtech blog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>ja</language>
        <lastBuildDate>Sat, 18 Mar 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://snitch0.github.io/tags/deepl/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>AI新時代の2023年を生き抜くためにAIを学ぶ①</title>
        <link>https://snitch0.github.io/p/ai-translate/</link>
        <pubDate>Sat, 18 Mar 2023 00:00:00 +0000</pubDate>
        
        <guid>https://snitch0.github.io/p/ai-translate/</guid>
        <description>&lt;h2 id=&#34;空前のaiブーム&#34;&gt;空前のAIブーム&lt;/h2&gt;
&lt;p&gt;この記事にたどり着いた方々には言うまでも無いと思うけど、記事作成時点ではGPT-4が発表された直後で、&lt;a class=&#34;link&#34; href=&#34;https://www.nikkei.com/article/DGXZQOGN1653T0W3A310C2000000/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Microsoft&lt;/a&gt;や&lt;a class=&#34;link&#34; href=&#34;https://thebridge.jp/2023/03/google-announces-new-generative-ai-lineup-in-advance-of-microsofts-rumored-gpt-4-debut&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Google&lt;/a&gt;が自社プロダクトにAIコンテンツ作成機能を標準搭載することを発表するなど、大盛り上がりです。&lt;/p&gt;
&lt;p&gt;昨年12月にChatGPTが公開されてちょっと試した時の感想は、「&lt;strong&gt;なんか凄まじく自然な会話してくるけど、こいつ結構嘘つくな&lt;/strong&gt;」でした。息をするかの如く嘘を吐くため、まだシンギュラリティとは言えないかな～と思っていました。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://snitch0.github.io/p/ai-translate/okumurakosuke.png&#34;
	width=&#34;757&#34;
	height=&#34;451&#34;
	srcset=&#34;https://snitch0.github.io/p/ai-translate/okumurakosuke_hu832e5aea8e65028e9e366dde23279b29_70150_480x0_resize_box_3.png 480w, https://snitch0.github.io/p/ai-translate/okumurakosuke_hu832e5aea8e65028e9e366dde23279b29_70150_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;適当にでっちあげた名前を聞くと大ボラを吹き出すChatGPTさん。こんな人物は存在しない。自分の本名で聞いてみたら、ノーベル賞受賞歴のある物理学者だと言われた。&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;167&#34;
		data-flex-basis=&#34;402px&#34;
	
&gt;&lt;/p&gt;

&lt;blockquote class=&#34;md-hint info&#34;&gt;

ちなみに、シンギュラリティを「人工知能が人類を越えた瞬間」と定義したのはレイ・カーツワイルで、
&lt;b&gt;&lt;a href=&#34;https://www.amazon.co.jp/%E3%82%B7%E3%83%B3%E3%82%AE%E3%83%A5%E3%83%A9%E3%83%AA%E3%83%86%E3%82%A3%E3%81%AF%E8%BF%91%E3%81%84-%E3%82%A8%E3%83%83%E3%82%BB%E3%83%B3%E3%82%B9%E7%89%88-%E4%BA%BA%E9%A1%9E%E3%81%8C%E7%94%9F%E5%91%BD%E3%82%92%E8%B6%85%E8%B6%8A%E3%81%99%E3%82%8B%E3%81%A8%E3%81%8D-%E3%83%AC%E3%82%A4%E3%83%BB%E3%82%AB%E3%83%BC%E3%83%84%E3%83%AF%E3%82%A4%E3%83%AB/dp/414081697X&#34;&gt;著書「シンギュラリティは近い　人類が生命を超越するとき(2016)」&lt;/a&gt;&lt;/b&gt;がもとになっているらしい。今Amazonでポチった。後で読む。

&lt;/blockquote&gt;
&lt;iframe class=&#34;hatenablogcard&#34; style=&#34;width:100%;height:155px;&#34; src=&#34;https://hatenablog-parts.com/embed?url=https%3a%2f%2fwww.amazon.co.jp%2f%25E3%2582%25B7%25E3%2583%25B3%25E3%2582%25AE%25E3%2583%25A5%25E3%2583%25A9%25E3%2583%25AA%25E3%2583%2586%25E3%2582%25A3%25E3%2581%25AF%25E8%25BF%2591%25E3%2581%2584-%25E3%2582%25A8%25E3%2583%2583%25E3%2582%25BB%25E3%2583%25B3%25E3%2582%25B9%25E7%2589%2588-%25E4%25BA%25BA%25E9%25A1%259E%25E3%2581%258C%25E7%2594%259F%25E5%2591%25BD%25E3%2582%2592%25E8%25B6%2585%25E8%25B6%258A%25E3%2581%2599%25E3%2582%258B%25E3%2581%25A8%25E3%2581%258D-%25E3%2583%25AC%25E3%2582%25A4%25E3%2583%25BB%25E3%2582%25AB%25E3%2583%25BC%25E3%2583%2584%25E3%2583%25AF%25E3%2582%25A4%25E3%2583%25AB%2fdp%2f414081697X&#34; width=&#34;300&#34; height=&#34;150&#34; frameborder=&#34;0&#34; scrolling=&#34;no&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;今年に入ってからは「ChatGPTでこんなことさせてみた」系の記事が増えてきて、2月末くらいには&amp;quot;Prompting&amp;quot;(欲しい情報をAIから引き出すための、良い質問の仕方)みたいなものが成熟してきたように思います。&lt;/p&gt;
&lt;p&gt;この時点ですら私はまだ懐疑的で、&lt;strong&gt;いずれAIは質問の意図もうまく汲んでくれるようになるんだからPromptingを研究するなんて時間の無駄だろう&lt;/strong&gt;と思っていました。だからChatGPTは遊び程度にしか使っていなかった。&lt;/p&gt;
&lt;p&gt;しかし三月に入って少々暇ができた折、NotionAIやPerplexity、Phindといったサービスに触れてみたところ&lt;mark&gt;&lt;b&gt;AIサービス使いこなせないと俺が失業する&lt;/b&gt;&lt;/mark&gt;というか、&lt;mark&gt;&lt;b&gt;完璧なPromptingで調教されたAIは既に俺の能力を上回っている&lt;/b&gt;&lt;/mark&gt;という強い危機感を感じるまでに質が高かったので、慌てて勉強を始めました。&lt;/p&gt;
&lt;h2 id=&#34;今回検討したこと--翻訳機&#34;&gt;今回検討したこと ⇒ 翻訳機&lt;/h2&gt;
&lt;p&gt;Promptingも勉強していますが、まずは足下の作業効率UPからはじめようと思い英語の翻訳に取り組むことにしました。&lt;/p&gt;
&lt;p&gt;私が英語翻訳機能を欲するときは以下のような時です。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ネットサーフィン時    ⇒ deeplのChrome拡張で満足している&lt;/li&gt;
&lt;li&gt;論文を読みこむ時  ⇒ ちょこちょこdeepl使いつつ原文で読むのでChrome拡張で良い&lt;/li&gt;
&lt;li&gt;論文探しをするとき    ⇒ &lt;strong&gt;Inoreader上で日本語で素早くザッピングしたい&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;ニュースサイトを読んでるとき  ⇒ &lt;strong&gt;よほど読み込みたい場合でなければ日本語で素早く読みたい&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一番改善したいのが、RSSリーダーのInoreaderでニュースを漁っている時。どうしても英語が母国語ではないので、英語タイトルが並ぶ&lt;strong&gt;目が滑る&lt;/strong&gt;んですよね。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://snitch0.github.io/p/ai-translate/inoreader.png&#34;
	width=&#34;778&#34;
	height=&#34;626&#34;
	srcset=&#34;https://snitch0.github.io/p/ai-translate/inoreader_hub1dcd0927cfdc8045379d8b8acdd5cab_196012_480x0_resize_box_3.png 480w, https://snitch0.github.io/p/ai-translate/inoreader_hub1dcd0927cfdc8045379d8b8acdd5cab_196012_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Inoreaderの英語フィード例。朝起きてすぐだと全然記事を選別できなかったりする。&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;124&#34;
		data-flex-basis=&#34;298px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;今の自分のニーズとしては&lt;strong&gt;それなりにボリュームのある記事・論文&lt;/strong&gt;を&lt;strong&gt;なんらかのアプリケーション上で&lt;/strong&gt;、&lt;b&gt;手っ取り早く読みたい(要旨が分かれば良い)&lt;/b&gt;という形に落ち着きそうなので、基本的にはDeeplコピペだとかChrome拡張を使うなどではなく、APIを使ってプログラムを走らせる前提で検討してみることにしました。&lt;/p&gt;
&lt;h2 id=&#34;翻訳機の候補者たち&#34;&gt;翻訳機の候補者たち&lt;/h2&gt;
&lt;h3 id=&#34;deepl&#34;&gt;DeepL&lt;/h3&gt;
&lt;p&gt;翻訳といったらこれ！もう日本人研究者でDeepLを知らない人はいないのでは？&lt;/p&gt;
&lt;p&gt;DeepLが有名になる前は「&lt;a class=&#34;link&#34; href=&#34;https://miraitranslate.com/trial/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;みらい翻訳&lt;/a&gt;」というツールを良く使ってましたが、最近ではDeepLの方が使い勝手が良くなってしまいました。&lt;/p&gt;
&lt;p&gt;無料と有料のAPIが提供されています。無料でも500,000単語までいけるので、本格的に業務利用しない限り無料APIで事足りる可能性が十分あります。&lt;/p&gt;

&lt;blockquote class=&#34;md-hint info&#34;&gt;

参考までに、&lt;u&gt;&lt;a href=&#34;[url](https://blog.fostergrant.co.uk/2017/08/03/word-counts-popular-books-world/)&#34;&gt;ハリーポッターシリーズ全部の単語数を会わせても1,084,170単語&lt;/a&gt;&lt;/u&gt;であることを踏まえると、500,000単語はすさまじく多い気がする。

&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://snitch0.github.io/p/ai-translate/deepl_api.png&#34;
	width=&#34;644&#34;
	height=&#34;713&#34;
	srcset=&#34;https://snitch0.github.io/p/ai-translate/deepl_api_hueb60472492fb782b0c9ec12750c75cdb_36349_480x0_resize_box_3.png 480w, https://snitch0.github.io/p/ai-translate/deepl_api_hueb60472492fb782b0c9ec12750c75cdb_36349_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;DeepLのAPI料金プラン&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;90&#34;
		data-flex-basis=&#34;216px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;DeepLの難点は、やはり字数制限があるところでしょうか。実際に運用してみないと分からないものの、私がInoreaderでサブスクライブしているフィードを通じて目にする論文だけで週に500本くらい、海外ニュースサイトの記事は一日で1000本くらいあります。全部を全文翻訳しないにせよこれを全て翻訳したら大変なことになりそうです。&lt;/p&gt;
&lt;h3 id=&#34;openai-api&#34;&gt;OpenAI API&lt;/h3&gt;
&lt;p&gt;ChatGPTをちょこちょこ使ってますが、翻訳もそれなりにできるそうなので試してみました。&lt;/p&gt;
&lt;p&gt;APIは有料です。今回使用したモデルは&lt;a class=&#34;link&#34; href=&#34;https://openai.com/pricing&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1K token使っても$0.02&lt;/a&gt;。なーんだ安いじゃんと思いきや、&lt;a class=&#34;link&#34; href=&#34;https://zenn.dev/umi_mori/books/chatbot-chatgpt/viewer/how_to_calculate_openai_api_prices&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;トークンとはなんぞや&lt;/a&gt;と調べると、記事一本で普通に1K token使ってもいっちゃいそうです。普通にChatするだけなら文字数少ないのでトークンも少なくて済むのに、翻訳は大量の文章を投げざるを得ないのでコストが嵩んでしまう模様。&lt;/p&gt;
&lt;p&gt;ちなみに、今回の検討で何度かネット記事をAPIに投げましたが、現時点での支払い額は&lt;code&gt;$0.11&lt;/code&gt;となっています。&lt;strong&gt;お試しでこれくらいなので先行きが不安です・・・&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;notionai&#34;&gt;NotionAI&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://snitch0.github.io/p/ai-translate/notionai.png&#34;
	width=&#34;933&#34;
	height=&#34;523&#34;
	srcset=&#34;https://snitch0.github.io/p/ai-translate/notionai_hu3884173228d38f8044329f3422f28128_58754_480x0_resize_box_3.png 480w, https://snitch0.github.io/p/ai-translate/notionai_hu3884173228d38f8044329f3422f28128_58754_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;178&#34;
		data-flex-basis=&#34;428px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;NotionAIはライティングツールのNotionで使えるツールです。文章の要約、翻訳、あるいはゼロからの記事作成などが可能なサービスで、既存のNotionプランとは別に$ 10/mo.(年払いディスカウント有)がかかります。&lt;/p&gt;
&lt;p&gt;私はもう二三年くらいNotionを愛用していて、proプランに課金し続けていて、タスク管理やアイデアノート、Wordに起こす前の草稿作成などに使っています。JTC企業研究員という仕事柄、ガチの業務文書はNotionに書かないようにしていましたが、ボヤっとした備忘録的な日誌として業務内容を書いたりはしていました。&lt;/p&gt;
&lt;p&gt;そんなNotionにもAI執筆が搭載されたわけですが、最近のMicrosoftやGoogleのムーブを少し先取りしていたような感じで、リリース当初は結構斬新な機能だったと思います。この文章を表に変換、みたいな操作ができますからね。少し使ってめちゃくちゃ便利だと思ったので即課金しました。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://snitch0.github.io/p/ai-translate/notion_script_to_table.png&#34;
	width=&#34;861&#34;
	height=&#34;531&#34;
	srcset=&#34;https://snitch0.github.io/p/ai-translate/notion_script_to_table_hu7d6f0dbfd5c333fa34e4aae850535e49_52509_480x0_resize_box_3.png 480w, https://snitch0.github.io/p/ai-translate/notion_script_to_table_hu7d6f0dbfd5c333fa34e4aae850535e49_52509_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;文章から表を作成するNotionAIさん。GPT-4ほど賢いようには見えないが、十分実用的。&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;162&#34;
		data-flex-basis=&#34;389px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;いざ翻訳テスト&#34;&gt;いざ翻訳テスト！&lt;/h2&gt;
&lt;p&gt;今回は適当な新聞記事を選んできました。選んだのは&lt;a class=&#34;link&#34; href=&#34;https://www.socialmediatoday.com/news/Meta-Developing-Decentralized-Twitter-Alternative/644730/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Meta社がTwitterライクアプリを作成中？ということを報じた記事&lt;/a&gt;です。&lt;/p&gt;
&lt;iframe class=&#34;hatenablogcard&#34; style=&#34;width:100%;height:155px;&#34; src=&#34;https://hatenablog-parts.com/embed?url=https%3a%2f%2fwww.socialmediatoday.com%2fnews%2fMeta-Developing-Decentralized-Twitter-Alternative%2f644730%2f&#34; width=&#34;300&#34; height=&#34;150&#34; frameborder=&#34;0&#34; scrolling=&#34;no&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;権利的に配慮して、冒頭だけを引用します。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Meta’s Developing a Decentralized Twitter Alternative, According to Reports&lt;/p&gt;
&lt;p&gt;With many Twitter users unhappy about the platform’s changes under Elon Musk, and amid a growing push towards a new approach to social networking, with alternative systems of moderation and management, Meta is looking to seize the opportunity, by launching its own, Twitter-like social app, which will be focused on short, text-based updates.&lt;/p&gt;
&lt;p&gt;As reported by Platformer and MoneyControl, Meta’s developing a new platform, currently titled ‘P92’, which sounds very similar to a Twitter feed, and interestingly, would be decentralized, aligning with the new wave social media push.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;久方ぶりに自力で日本語訳を試みます。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;メタ社が分散型ツイッター代替アプリを開発中、報道&lt;/p&gt;
&lt;p&gt;イーロンマスクのもとでTwitterというプラットフォームが変わってしまったことを多くのTwitterユーザーが嘆いている今の状況、そして新しい形のモデレーションやマネージメントシステムをもったソーシャルネットワーキングの新しいアプローチの開発を迫られている状況で、メタ社はTwitterライクなソーシャルアプリを自社でローンチする機会を掴もうとしています。このアプリは短文の、テキストベースの更新に焦点を当てられたものになるでしょう。&lt;/p&gt;
&lt;p&gt;PlatformerとMoneyControlで報じられたように、メタ社は今のところ「P92」と名付けられている新しいプラットフォームを開発中です。これはTwitterのフィードに非常によく似たものになりそうであり、また興味深いことに分散型であり、ソーシャルメディアの新しいトレンドの波に乗ったものになると言えるかもしれません。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;英語で書かれた記事を頻繁に読むわけではないのですが、上から下まで一読できるような文法をあえて使っているのかな、という気がしました。口語的というか。&lt;/p&gt;
&lt;p&gt;では、この文章をAIに投げて翻訳させてみます。&lt;/p&gt;
&lt;h3 id=&#34;deepl-1&#34;&gt;DeepL&lt;/h3&gt;
&lt;p&gt;まずDeepL APIを使ったバージョンです。今回はフリー版を使っての実装です。なお、&lt;mark&gt;このコードはChatGPTが生成したコードをほんの少しだけ修正しただけのものです&lt;/mark&gt;。&lt;/p&gt;
&lt;div&gt;
    &lt;div class=&#34;codeblock--content&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;requests&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# type: ignore&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;argparse&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;parser&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;argparse&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ArgumentParser&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;description&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Translation tool using DeepL API&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;parser&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;add_argument&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;-i&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;help&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Input file path&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;parser&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;add_argument&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;-o&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;help&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Output file path&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;parser&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;parse_args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;deepl.key&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;auth_key&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;strip&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;target_language&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;JA&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;source_language&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;EN&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;url&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;https://api-free.deepl.com/v2/translate&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;params&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s2&#34;&gt;&amp;#34;auth_key&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;auth_key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s2&#34;&gt;&amp;#34;target_lang&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target_language&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s2&#34;&gt;&amp;#34;source_lang&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;source_language&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s2&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;response&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;post&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;url&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;params&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;translated_text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;json&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;translations&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;o&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;w&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;write&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;translated_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;DeepLのドキュメンテーションも読まずにコード実行したところ403エラー。調べたところフリー版と有料版とではURLが異なるらしく、そこだけ修正しました。&lt;/p&gt;
&lt;h4 id=&#34;deeplライブラリを使った別の実装&#34;&gt;DeepLライブラリを使った別の実装&lt;/h4&gt;
&lt;p&gt;記事書きながら公式のドキュメント読んでたら気づきましたが、&lt;a class=&#34;link&#34; href=&#34;https://github.com/DeepLcom/deepl-python&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;python用の公式ライブラリ&lt;/a&gt;があったんですね😢&lt;/p&gt;
&lt;p&gt;こちらの方が簡単そうだったので、サクッと実装してみました。&lt;/p&gt;
&lt;div&gt;
    &lt;div class=&#34;codeblock--content&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;deepl&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;argparse&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;parser&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;argparse&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ArgumentParser&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;description&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Translation tool using DeepL API&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;parser&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;add_argument&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;-i&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;help&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Input file path&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;parser&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;add_argument&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;-o&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;help&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Output file path&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;parser&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;parse_args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;deepl.key&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;auth_key&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;strip&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;translator&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;deepl&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Translator&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;auth_key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;target_language&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;JA&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;translator&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;translate_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target_lang&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;target_language&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;o&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;w&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;write&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;非常にpythonicで良い実装になったと思います。&lt;/p&gt;
&lt;h4 id=&#34;結果&#34;&gt;結果&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;Metaが分散型Twitterの代替案を開発中との報道あり&lt;/p&gt;
&lt;p&gt;イーロン・マスクのもとでのTwitterの変化に不満を持つユーザーが多い中、モデレーションや管理システムなど新しいソーシャルネットワークのあり方を模索する声が高まる中、メタは、短いテキストベースの更新に焦点を当てた独自のTwitterライクなソーシャルアプリを発表し、この機会を捉えようと考えています。&lt;/p&gt;
&lt;p&gt;PlatformerやMoneyControlが報じたように、Metaは現在「P92」と題された新しいプラットフォームを開発中で、Twitterフィードに非常に似ているように聞こえるが、興味深いことに、分散型であり、新しい波のソーシャルメディアの推進に沿うものである。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;完璧です:star2: ところどころ自分の翻訳がおかしいところに気づかされます。&lt;/p&gt;
&lt;p&gt;細かいところの翻訳漏れがなく、タイトルも記事っぽい言い回しへと自動で言い換えているところが素晴らしいと思います。&lt;/p&gt;
&lt;p&gt;全く問題ないので、普段使いに採用しても全く問題なし。&lt;/p&gt;
&lt;h3 id=&#34;chatgpt&#34;&gt;ChatGPT&lt;/h3&gt;
&lt;p&gt;OpenAIのAPIには&lt;a class=&#34;link&#34; href=&#34;https://platform.openai.com/docs/models&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;様々なモデル&lt;/a&gt;が用意されています。はじめはGPT-3.5のdavinciを使って試しましたが、なぜか長文の結果を出力することができず途中で途切れてしまったため、GPT-3.5-turboを使用しました。前者は一つのプロンプトだけを投げる用、後者は対話のプロンプト形式用です。&lt;mark&gt;以下のコードもChatGPTにて生成したコードを少しだけ改変したものです&lt;/mark&gt;。&lt;/p&gt;
&lt;div&gt;
    &lt;div class=&#34;codeblock--content&#34;&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;openai&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;argparse&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;openai&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;api_key_path&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;api.key&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;parser&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;argparse&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ArgumentParser&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;description&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Translation tool using OpenAI-api&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;parser&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;add_argument&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;-i&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;help&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Input file path&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;parser&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;add_argument&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;-o&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;help&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Output file path&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;parser&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;add_argument&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;--model&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;text-davinci-002&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;parser&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;parse_args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;translate_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;input_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;openai&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ChatCompletion&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;create&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;gpt-3.5-turbo&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;system&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;あなたはプロの翻訳家です。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;user&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;以下の文章を英語から日本語に翻訳してください。 &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;input_text&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;choices&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;message&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;strip&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;utf-8&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;input_text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;translated_text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;translate_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;input_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;o&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;w&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;utf-8&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;write&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;translated_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;結果-1&#34;&gt;結果&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;報道によると、Meta社は分散型のTwitterの代替案を開発しています。&lt;/p&gt;
&lt;p&gt;Elon Muskの下でプラットフォームの変更に不満を持つTwitterユーザーが多く、代替的なモデレーションや管理システムに向けた押しの中で、Meta社は自社のTwitterライクなソーシャルアプリを立ち上げることでこの機会をつかもうとしています。&lt;/p&gt;
&lt;p&gt;PlatformerやMoneyControlによると、Meta社は現在「P92」という名称の新しいプラットフォームを開発中で、Twitterフィードに非常に似ており、興味深いことに分散型であり、新しいソーシャルメディアの波に合致しています。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;DeepLに比べるとワンランクダウンした感じがします。しかし、Google Translateに比べたらよっぽどマシな性能です。&lt;/p&gt;
&lt;p&gt;「～に向けた押しの中で」といか、「新しいソーシャルメディアの波に合致しています」という部分は翻訳に苦労していそう。&lt;/p&gt;
&lt;p&gt;とは言えこれは全然アリです。普段使い用のAPIにしても良いくらい。&lt;/p&gt;
&lt;h3 id=&#34;notionai-1&#34;&gt;NotionAI&lt;/h3&gt;
&lt;p&gt;NotionAIはNotionのページ内で起動します。APIでは使えないので比較対象にならなそうですが、「記事をNotionにスクラップして、NotoinAPIで自動翻訳」という荒技が可能です。これはこれで実用的なソリューション。&lt;/p&gt;

&lt;blockquote class=&#34;md-hint info&#34;&gt;

NotionはProアカウントにアップグレードすることで無制限に画像等をアップロードできるようになります。インターネット記事をスクラップし放題になるというこの恩恵があるから私はお金を払い続けています。

&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://snitch0.github.io/p/ai-translate/notionai_translation.png&#34;
	width=&#34;658&#34;
	height=&#34;522&#34;
	srcset=&#34;https://snitch0.github.io/p/ai-translate/notionai_translation_hue2caca6c56b93ec6a98a0866f50542d4_36886_480x0_resize_box_3.png 480w, https://snitch0.github.io/p/ai-translate/notionai_translation_hue2caca6c56b93ec6a98a0866f50542d4_36886_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;NotionAIは書いておいた文章・表などを選択してからAIを起動する。要約や翻訳はプロンプトを書かなくても起動できる。&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;126&#34;
		data-flex-basis=&#34;302px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;結果-2&#34;&gt;結果&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;報道によると、Metaは分散型のTwitter代替アプリを開発しているとのことです。&lt;/p&gt;
&lt;p&gt;Elon Muskの下でプラットフォームの変更に不満を持つ多くのTwitterユーザーや、モデレーションや管理の新しいアプローチに向けた新しいソーシャルネットワーキングシステムの成長の中、Metaは機会をつかむために、短いテキストベースの更新に焦点を当てたTwitterのようなソーシャルアプリを立ち上げることを計画しているようです。&lt;/p&gt;
&lt;p&gt;PlatformerやMoneyControlによると、Metaは現在「P92」というタイトルの新しいプラットフォームを開発中で、Twitterのフィードに非常に似ており、興味深いことに分散型になる予定で、新しいソーシャルメディアの流れと一致しています。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;翻訳内容は間違ってはいないのですが、人に読ませる文章としてはどこかぎこちない。というか、一読してもなんか頭に入ってこない。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Elon Muskの下でプラットフォームの変更に不満を持つ多くのTwitterユーザーや&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;この文章は本来、「～という状況」かつ「～という状況」の中で「MetaはTwitter代替アプリを開発」という長い一文の冒頭部分なので、「～や」と次に続く文章を示唆する助詞を使うと読み手にはわかりにくくなってしまいますよね。これでは実用レベルとはいえません。&lt;/p&gt;
&lt;h3 id=&#34;番外編-google-translate&#34;&gt;番外編 Google Translate&lt;/h3&gt;
&lt;h4 id=&#34;結果-3&#34;&gt;結果&lt;/h4&gt;
&lt;p&gt;「Google Translateは使い物にならん」前提で書いてきましたが、実際のところどうなんでしょう？&lt;/p&gt;
&lt;p&gt;気になったので試してみました。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;報告によると、Meta は分散型 Twitter の代替手段を開発中&lt;/p&gt;
&lt;p&gt;多くの Twitter ユーザーが Elon Musk の下でのプラットフォームの変更に不満を持っており、モデレーションと管理の代替システムを使用したソーシャル ネットワーキングへの新しいアプローチへの圧力が高まる中で、Meta は独自の Twitter のようなサー&amp;gt;ビスを開始することで、この機会をつかもうとしています。 短いテキストベースの更新に焦点を当てたソーシャルアプリ。&lt;/p&gt;
&lt;p&gt;Platformer と MoneyControl によって報告されたように、Meta は現在「P92」というタイトルの新しいプラットフォームを開発しています。これは Twitter フィードに非常に似ており、興味深いことに、新しい波のソーシャル メディア プッシュに合わせて分散化されるでしょう。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;意外に悪くない・・・？と思いきや、一番肝心の「分散型」というキーワードを知らないせいか、かんか直訳感があります。&lt;/p&gt;
&lt;p&gt;NotionAIよりはすらすら読めるような気がするような・・・🤔？&lt;/p&gt;
&lt;p&gt;「新しい波のソーシャル　メディア　プッシュに会わせて分散化されるでしょう」&lt;/p&gt;
&lt;p&gt;にしても、この文章はいくらなんでも謎ｗ　Google Translateは相変わらずな感じ。&lt;/p&gt;
&lt;h2 id=&#34;結論やっぱりdeeplが最強&#34;&gt;結論:やっぱりDeepLが最強&lt;/h2&gt;
&lt;p&gt;DeepLは読みやすいし、内容がすらすら頭に入ってくる。それ以外は読んでいくと途中でつまづくような、そんな違和感がありました。&lt;/p&gt;
&lt;p&gt;OpenAIのAPIも今回初めて使ってみましたが、意外にお金がかかることに気がつきました。本格的に業務利用するまでは控えておこう。&lt;/p&gt;
&lt;p&gt;今度はDeepLAPIでInoreaderのヘッドラインを自動翻訳する仕組みを作りたい。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>生物系研究者のためのChatGPT入門</title>
        <link>https://snitch0.github.io/p/ai-translate/</link>
        <pubDate>Sat, 18 Mar 2023 00:00:00 +0000</pubDate>
        
        <guid>https://snitch0.github.io/p/ai-translate/</guid>
        <description>&lt;h2 id=&#34;この記事ではchatgptに関する誤解を解きます&#34;&gt;この記事ではChatGPTに関する誤解を解きます&lt;/h2&gt;
&lt;p&gt;2022年末にChatGPTが一般向けにリリースされた時はエンジニア界隈と機械学習界隈が盛り上がるだけでしたが、GPT4をベースにしたChatGPTがリリースされた2023年3月以降はテレビや新聞でも大々的に取り上げられるようになり、世界中の人たちが汎用AIに注目するようになりましたね。そもそも機械学習の原理に明るくない人からすると突然人間に取って代わるようなAIが登場したので、ターミネーターのスカイネット・マトリックスの機械世界のような未来がすぐそばまで来ているのではないか？といった漠然とした恐怖が広がっている節があるように思います。&lt;/p&gt;
&lt;p&gt;また、ChatGPTはよく分からんけど凄い！という文脈でもChatGPTを過大評価しているようなケースも多く見受けられます。特に、以前述べたHallucination&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;の危険性を知らずに「この利用法はスゲーだろ！」と声高らかにTwitterでシェアしている方がちらほら見受けられることに危険性を感じます。さらに怖いのは、かつてのWeb3信者のような盲信的サポーターがこうしたデマを無条件に信じてしまっていることです。&lt;/p&gt;
&lt;p&gt;Twitterの世直しは私には荷が重すぎるので、少なくとも私の周囲の方々がChatGPTを上手に扱うお手伝いができれば良いな、と思ってこの記事を作成しています。&lt;/p&gt;
&lt;h3 id=&#34;この記事を読むとこんなことが分かる&#34;&gt;この記事を読むとこんなことが分かる&lt;/h3&gt;
&lt;p&gt;この記事では以下の内容を深掘りしていこうと思います。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ChatGPTとGPT、、、って何？&lt;/li&gt;
&lt;li&gt;GPTは&amp;quot;思考&amp;quot;をしない、ただの確率モデルである&lt;/li&gt;
&lt;li&gt;ChatGPTは事実ではないことを、さも事実かのように述べる&lt;/li&gt;
&lt;li&gt;ChatGPTは2021年以降の事を知らない&lt;/li&gt;
&lt;li&gt;ChatGPTは計算ができない&lt;/li&gt;
&lt;li&gt;個人情報は入力しちゃ絶対だめ！&lt;/li&gt;
&lt;li&gt;ChatGPTが得意なことは作文とプログラミング&lt;/li&gt;
&lt;li&gt;GPTは近い将来あらゆるアプリに組み込まれる&lt;/li&gt;
&lt;li&gt;生物系研究者はAIをどう活用すべきか&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote class=&#34;md-hint danger&#34;&gt;

この記事の執筆者は深層学習やLLMの研究の専門家ではなく、機械学習やゲノム解析を専門とする生物情報学の研究者です。
GPTに関して間違った説明をしていたら教えていただけますと幸いです。

&lt;/blockquote&gt;
&lt;h2 id=&#34;chatgptとgptって何&#34;&gt;ChatGPTとGPT、、、って何？&lt;/h2&gt;
&lt;p&gt;ChatGPTはGPTという言語モデルを使ったサービスの名前です。GPTとは、Generalized Pretrained Transformerの略で、Transformerという言語モデルをベースに汎用AIとして深層学習させた言語モデルの一種です。&lt;/p&gt;
&lt;p&gt;いきなり難しい言葉が沢山でてきましたね。まずは深層学習から始めて、一つずつ説明していきます。&lt;/p&gt;
&lt;h3 id=&#34;深層学習とは&#34;&gt;深層学習とは&lt;/h3&gt;
&lt;p&gt;深層学習とは、ニューラルネットワークを祖とする機械学習モデルの一種です。機械学習と聞くと難しそうな雰囲気がしますが、最小自乗法の線形回帰だって機械学習です。要は数式を枠組みとして用意しておいて、データをうまく説明出来るように係数を推定しているのです。ニューラルネットワーク以前は本当にシンプルな数式ですべての自然現象を説明しようと頑張っていました。多項式回帰や重回帰、ランダムフォレストなどがこの分野に該当します。&lt;/p&gt;
&lt;p&gt;ニューラルネットワークは文字通り生物の神経組織を模したもので、これまた機械学習の一種です。複数のニューロンが複数のニューロンから情報を受け取り、時にはその情報信号を増強したり抑制したりしながらこねくり回しつつ、最後にはシンプルな結果を出力するというものです。データをうまく説明できるように学習させる際には、この情報の増強/抑制の程度を推定します。深層学習はニューラルネットワークの層を増やして、深くしたものと考えておけば良いと思います。画像処理や言語処理など様々な分野において、深層学習はものの数年でそれまでの研究史を塗り替えるような高い精度の予測モデルを実現してきたため、2010年代後半のAIブームを支えてきました。&lt;/p&gt;
&lt;p&gt;もう一度ChatGPTに話を戻すと、ChatGPTはこの深層学習がベースになっています。機械学習を通じて、文字列情報を入力として受け取り、情報を多層のニューラルネットワークに通して、なんらかの文字列情報を出力する確率モデルを作り出しています。機械学習によって作り出された確率モデルがGPT-3.5やGPT-4です。&lt;/p&gt;
&lt;p&gt;確率モデルの話はこの後の「GPTは&amp;quot;思考&amp;quot;をしない、ただの確率モデルである」にて説明します。&lt;/p&gt;
&lt;h3 id=&#34;gptはどういう経緯で生まれたか&#34;&gt;GPTはどういう経緯で生まれたか&lt;/h3&gt;
&lt;p&gt;ニューラルネットワークの発想はアラン・チューリングが&amp;quot;On Computable Numbers&amp;quot;(1937)で既に述べており、ジョンフォンノイマンらがその応用方法などについても示していましたが、今ほどは流行っていませんでした。その理由は単純で、当時の機械学習モデルは精度が良くなかったのです。&lt;/p&gt;
&lt;p&gt;今のAIブームは&lt;a class=&#34;link&#34; href=&#34;https://dl.acm.org/doi/10.1145/3065386&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2012年に発表されたジェフェリー・ヒントンらの論文&lt;/a&gt;がきっかけになっています。この論文はImageNet Large Scale Visual Recognition Challengeというコンペで彼らが優勝したときの手法を述べたもので、深層学習を使っていました。ポイントは畳み込み層というものを用意したことや、情報の増幅/抑制にReLU関数というものを導入したことでした。また、膨大な計算をGPUで高速に処理できるよう実装したことも現代的な深層学習にも通ずるポイントです。実のところジェフェリー・ヒントンらのモデルの精度を上回るものが翌年には出てきたため、つかの間のベスト精度だったわけですが、畳み込みニューラルネットワークをベースとして、活性化関数にReLU関数に採用するだけで、様々な画像認識タスクでいとも簡単に良い精度のモデルが作れるようになりました。ここから爆発的にAIブームが始まったと言われています。この時代はCNN(Convolutional Neural Network)の時代だと言われます。&lt;/p&gt;
&lt;p&gt;CNNは言語モデルにおいてはあまり役に立たないのですが、短期的な記憶能力を実装したRNN(Recurrent Neural Network)を使うことで自然言語タスクでも深層学習が活躍するようになります。しかし、RNNを使った言語モデルは長文に対応できないなどの致命的な欠点がありました。ブレイクスルーは&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1409.0473&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2014年のAttention機構&lt;/a&gt;とXX年のTransformerモデルの発表です。Attension機構は人間の認知科学を参考にしたもので、重要な部分のパラメーターを重くすることでデータの一部分に注目し、データ全体を的確に捉えようとするものです。XX年にGoogleから発表されたTransformerモデルは現在のGPT、GoogleのBardなど、昨今の全ての言語モデルの礎となった極めて重要なモデルです。Transformerモデルを発表した論文のタイトルはズバリ&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1706.03762&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;&amp;ldquo;Attention Is All You Need&amp;rdquo;&lt;/a&gt;。RNN層などは使わず、当時はサポーティブな技術だったAttetion機構をメインに採用した、画期的なモデルでした。&lt;/p&gt;
&lt;p&gt;Transformerは翻訳タスクにおいて非常に良い性能を発揮しました。どれくらい良い性能だったかと言うと、未知単語は無いという条件のもとでは数十年かけて構築されてきた過去の言語モデルに匹敵する精度だったのです。Transformerモデルはこれまでの言語モデルの欠点を解決したモデルです。このモデルをベースに、Google、Meta、OpenAIなどが独自の学習データを用意し、独自のモデルを作るようになっていきます。&lt;/p&gt;
&lt;p&gt;Meta(旧Facebook)が作ったのはBERT(2018)という機械学習手法で、しばらくの間はBERTがこの業界のメインストリームでした。この頃、私の知人がBERTを使ったSNSのデータ分析をやりたがっていたのを覚えています。OpenAIはその間にMicrosoftの出資を受けながら現在のGPTを開発していました。その成果が今になって結実したということになります。&lt;/p&gt;

&lt;blockquote class=&#34;md-hint info&#34;&gt;

当時のAI開発は基本的にオープンソース(内部のプログラム等を全て公開する)で進められており、GAFAがバチバチと競争するような状況ではありませんでした。そのため、Transformerモデルのような画期的な発明でもプレプリントにサクッと公開してしまっていました。個人的には「協力して集合知で最強のAIを作ろうぜ！」という当時の雰囲気は結構好きでしたが、ChatGPT以降はクローズドソースも増えてきてしまいました。。

&lt;/blockquote&gt;
&lt;h3 id=&#34;巨大テック企業のai軍拡競争はなぜ起きたか&#34;&gt;巨大テック企業のAI軍拡競争はなぜ起きたか&lt;/h3&gt;
&lt;p&gt;元はといえばTransformerモデルはGoogleがオープンソースで発表したもの。しかし2023年現在ではOpenAIとMicrosoftがChatGPTで世界中の注目を集め、BaiduやGoogleがそれに追従する形になっています。なぜ他の企業が参入できないのでしょうか？&lt;/p&gt;
&lt;p&gt;その理由はTransformerが持つ重要な性質である、&amp;ldquo;Scaling-law&amp;quot;にあると思います。&lt;/p&gt;
&lt;p&gt;Scaling-lawはOpenAIが発見し、&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2001.08361&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2020年に報告しました&lt;/a&gt;。Scaling-lawを一言で説明するなら、「金をかければかけるほど、データを増やせば増やすほど、Transformerモデルの性能は青天井に向上する」ということです。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://snitch0.github.io/p/ai-translate/scalinglaw.png&#34;
	width=&#34;775&#34;
	height=&#34;335&#34;
	srcset=&#34;https://snitch0.github.io/p/ai-translate/scalinglaw_hu7455cdfd3a32976f4caefc4328110947_76019_480x0_resize_box_3.png 480w, https://snitch0.github.io/p/ai-translate/scalinglaw_hu7455cdfd3a32976f4caefc4328110947_76019_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;見れば分かるきれいな線形回帰やん。奇妙なほど線形性があります。&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;231&#34;
		data-flex-basis=&#34;555px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;通常こんなことは考えにくいのです。なぜなら、どんな機械学習だって普通は過学習(over-fitting)が起き、どこかで性能の限界が来るからです。過学習とは、簡単に言えば学習データに最適化しすぎて未知の問題をうまく答えられなくなる現象のことです。小テストばっかり勉強しすぎて本番のテストにうまく答えられない、みたいな感じです。この過学習はいかなる機械学習でも起きうるので、通常は学習データを増やしすぎると性能がかえって低下するものです。&lt;/p&gt;
&lt;p&gt;もちろんいつかTransformerの限界は来るのかもしれませんが、少なくともまだ限界は見えていません。この重要な性質があるため、私たちのような持たぬ者は彼らに対抗できないのです。GAFAが巨額の資金を投入して作ったモデルに我々が勝てる見込みは無く、しかもお金をかければかけるほど性能が上がるわけです。&lt;/p&gt;
&lt;p&gt;ちなみに、GAFAがどうやって機械学習を行っているかですが、&lt;a class=&#34;link&#34; href=&#34;https://cloud.google.com/tpu?hl=ja&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Googleは深層学習専用のプロセッサであるTPUを開発&lt;/a&gt;し、独自に大量の計算機を用意してBardを作りました。Metaは&lt;a class=&#34;link&#34; href=&#34;https://appmaster.io/ja/news/meta-aws-patonashitsupu-ai-risachi-pytorch-sapoto&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Amazonと提携&lt;/a&gt;し、AWSを使って研究を行っているものと推定されます。OpenAIは言わずもがな、MicrosoftのAzureが使えるでしょう。&lt;/p&gt;
&lt;h3 id=&#34;ここまでのまとめ&#34;&gt;ここまでのまとめ&lt;/h3&gt;
&lt;p&gt;専門用語がたくさん出てきたので理解が難しかったかもしれませんが、一度GPTについてまとめておきます。&lt;/p&gt;
&lt;p&gt;まず、GPTとは、Googleが発明したTransformerというモデルをベースに、OpenAIが開発した深層学習モデルのことでした。&lt;/p&gt;
&lt;p&gt;Transformerは言語処理に適した、画期的なモデルです。&amp;ldquo;Scaling-law&amp;quot;という特徴により、Transformerモデルはお金をかければかけるほど性能が向上し、2023年現在も「より大量のデータで、より性能の高いモデル」を作るべくGAFA(+α)が鎬を削っている状況です。&lt;/p&gt;
&lt;h2 id=&#34;gptは思考をしないただの確率モデルである&#34;&gt;GPTは&amp;quot;思考&amp;quot;をしない、ただの確率モデルである&lt;/h2&gt;
&lt;p&gt;ChatGPTを使っていると、あまりにもこちらの命令を的確に理解している(ように見える)ので、「GPTは賢い」とか「AIはなんでもできる」と思えますよね。しかし、GPTをはじめとする言語モデルはただ確率の高い文字を並べているだけなので、思考などはしていません。魂も脳も無い、ただの確率モデルに過ぎません。&lt;/p&gt;
&lt;p&gt;これはGPTがどのように作られたかを知ると分かりやすいかもしれません。&lt;/p&gt;
&lt;h3 id=&#34;gptの学習方法&#34;&gt;GPTの学習方法&lt;/h3&gt;
&lt;p&gt;ここまでの説明で、GPTが大量の文字列データを学習している事がお分かりかと思いますが、では学習とは具体的に何をしているのでしょうか？&lt;/p&gt;
&lt;p&gt;それは、虫食い問題をひたすら覚えているのです。「イギリスの首都は□□である。」が問い、正解データは「ロンドン」と言ったように、虫食いの文章を大量に覚えているのです。ベースとなる文章には世界中のWebサイトからクロール&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;してきた文章で、おそらく大量のデータを使用しています。GPTはクローズドソースのため、詳細は明らかにされていません。&lt;/p&gt;
&lt;h3 id=&#34;確率的言語モデル&#34;&gt;確率的言語モデル&lt;/h3&gt;
&lt;p&gt;結果として完成したモデルは、以下のように「我輩」に続く言葉を一つずつ確率的に導いています。ある種のメタファーで「GPTは夏目漱石を知っている」と捉えることもできますが、実際には最も確率の高い言葉を並べているだけです。&lt;/p&gt;
&lt;p&gt;ChatGPTでは文末に「英語から日本語に翻訳してください」と付ければ英語を日本語へ翻訳することが可能ですが、確率的に日本語が続きやすいという性質が反映されているだけなのです。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://snitch0.github.io/&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;NTTデータさんの分かりやすい例　出典:https://www.intellilink.co.jp/column/ai/2022/072800.aspx&#34;
	
	
&gt;&lt;/p&gt;
&lt;iframe class=&#34;hatenablogcard&#34; style=&#34;width:100%;height:155px;&#34; src=&#34;https://hatenablog-parts.com/embed?url=https%3a%2f%2fwww.intellilink.co.jp%2fcolumn%2fai%2f2022%2f072800.aspx&#34; width=&#34;300&#34; height=&#34;150&#34; frameborder=&#34;0&#34; scrolling=&#34;no&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;このように考えると、ChatGPTに関する多くの漠然とした不安は解消されるのではないでしょうか。ChatGPTは何も思考していません。ただ確率的に単語を並べて見せているだけです。ChatGPTは人間を支配しようとはしていません。ChatGPTに意思などそもそも無い(はず)なのですから。&lt;/p&gt;
&lt;h2 id=&#34;chatgptは事実ではないことをさも事実かのように述べる&#34;&gt;ChatGPTは事実ではないことを、さも事実かのように述べる&lt;/h2&gt;
&lt;h3 id=&#34;hallucinationとは&#34;&gt;Hallucinationとは&lt;/h3&gt;
&lt;p&gt;AIが事実に即していない情報を自信満々に語る現象のことをHallucinationと呼びます。(&lt;a class=&#34;link&#34; href=&#34;https://ja.wikipedia.org/wiki/%E5%B9%BB%E8%A6%9A_%28%E4%BA%BA%E5%B7%A5%E7%9F%A5%E8%83%BD%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Wikipedia: 幻覚(人工知能)&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;特にChatGPTのGPT-3.5(2022年末に公開され、現在フリー版として公開されているモデル)ではしばしばHallucinationが観察されており、人々はこれを「嘘つきだ」と言っています。&lt;/p&gt;
&lt;p&gt;これは結構難しい問題で、OpenAIはもちろん、各社がHallucinationが起きないような入力方法を検討したり、そもそもHallucinationしないようにファインチューニングした新しいモデルを作成しています。ちなみに、GPT-4はGPT-3.5よりもHallucinationが起きにくくなっているそうで、私も使っている限りかなり改善しているように思います。&lt;/p&gt;
&lt;iframe class=&#34;hatenablogcard&#34; style=&#34;width:100%;height:155px;&#34; src=&#34;https://hatenablog-parts.com/embed?url=https%3a%2f%2fwww.yomiuri.co.jp%2fnational%2f20230506-OYT1T50064%2f&#34; width=&#34;300&#34; height=&#34;150&#34; frameborder=&#34;0&#34; scrolling=&#34;no&#34;&gt;&lt;/iframe&gt;

&lt;iframe class=&#34;hatenablogcard&#34; style=&#34;width:100%;height:155px;&#34; src=&#34;https://hatenablog-parts.com/embed?url=https%3a%2f%2fpresident.jp%2farticles%2f-%2f68667%3fpage%3d1&#34; width=&#34;300&#34; height=&#34;150&#34; frameborder=&#34;0&#34; scrolling=&#34;no&#34;&gt;&lt;/iframe&gt;

&lt;iframe class=&#34;hatenablogcard&#34; style=&#34;width:100%;height:155px;&#34; src=&#34;https://hatenablog-parts.com/embed?url=https%3a%2f%2ftwitter.com%2fsearch%3fq%3dChatGPT%2520%25E3%2580%2580%25E5%2598%2598%26src%3dtyped_query&#34; width=&#34;300&#34; height=&#34;150&#34; frameborder=&#34;0&#34; scrolling=&#34;no&#34;&gt;&lt;/iframe&gt;

&lt;h3 id=&#34;hallucination対策はどうしたらよいか&#34;&gt;Hallucination対策はどうしたらよいか？&lt;/h3&gt;
&lt;p&gt;後述の別サービスを使うことが第一です。PerplexityやBingは出典情報を添付するため、ChatGPTよりはHallucinationが起きにくくなっています。&lt;/p&gt;
&lt;p&gt;第二に、適切なプロンプティングをすることです。プロンプティングとは、GhatGPTへの入力のことです。ChatGPTは「～～してください」という指令だけでプログラミング・作文・メール作成などあらゆるタスクをこなすことが出来るため、ChatGPTへの入力方法が様々検討されています。プロンプティングについては&lt;a class=&#34;link&#34; href=&#34;&#34; &gt;記事を作成しています&lt;/a&gt;ので、詳しくはそちらをご覧ください。&lt;/p&gt;
&lt;iframe class=&#34;hatenablogcard&#34; style=&#34;width:100%;height:155px;&#34; src=&#34;https://hatenablog-parts.com/embed?url=https%3a%2f%2ftwitter.com%2fsearch%3fq%3dChatGPT%2520%25E3%2580%2580%25E5%2598%2598%26src%3dtyped_query&#34; width=&#34;300&#34; height=&#34;150&#34; frameborder=&#34;0&#34; scrolling=&#34;no&#34;&gt;&lt;/iframe&gt;

&lt;h2 id=&#34;chatgptは2021年以降の事を知らない&#34;&gt;ChatGPTは2021年以降の事を知らない&lt;/h2&gt;
&lt;p&gt;そもそもGhatGPT-3.5は2019年まで、GPT-4は2021年までの情報を使って機械学習が行われています。2022年以降に現実世界で起きたことは何一つ知らないのです。&lt;/p&gt;
&lt;p&gt;一見それっぽいこと(例えば、論文を紹介してくるなど)を返答してくることがあっても、ファクトチェックをすれば今年の出来事は全てHallucinationで満たされているはずです。&lt;/p&gt;
&lt;h3 id=&#34;最新情報はchatgptに聞いてはならない&#34;&gt;最新情報はChatGPTに聞いてはならない&lt;/h3&gt;
&lt;p&gt;以上の理由から、2021年以降の事はChatGPTに聞いたところで、嘘の情報が返ってくる可能性大です。この現象はどうしようもないので、後述の別サービスを使う方が良いでしょう。&lt;/p&gt;
&lt;h3 id=&#34;bardもたまにhallucinationする&#34;&gt;BardもたまにHallucinationする&lt;/h3&gt;
&lt;p&gt;Bardは検索エンジンを&lt;/p&gt;
&lt;h2 id=&#34;chatgptは計算ができない&#34;&gt;ChatGPTは計算ができない&lt;/h2&gt;
&lt;p&gt;やってみれば分かりますが、ChatGPTは計算が苦手です。以下の文章題では明らかに13個が正解なのですが、堂々と計算式まで出しておきながら間違えています。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://snitch0.github.io/p/ai-translate/calc1.png&#34;
	width=&#34;820&#34;
	height=&#34;353&#34;
	srcset=&#34;https://snitch0.github.io/p/ai-translate/calc1_hue9643377d41d1a0555eb6c80b7f897da_44243_480x0_resize_box_3.png 480w, https://snitch0.github.io/p/ai-translate/calc1_hue9643377d41d1a0555eb6c80b7f897da_44243_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;簡単な算数もできないGPT3.5&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;232&#34;
		data-flex-basis=&#34;557px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;これもHallucinationと同じくOpenAIが以前から認識していた問題で、GPT4では改善しているそうです。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://snitch0.github.io/p/ai-translate/calc2.png&#34;
	width=&#34;763&#34;
	height=&#34;364&#34;
	srcset=&#34;https://snitch0.github.io/p/ai-translate/calc2_hu17550536d89a358f26990336e8e7515c_45029_480x0_resize_box_3.png 480w, https://snitch0.github.io/p/ai-translate/calc2_hu17550536d89a358f26990336e8e7515c_45029_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;GPT4ならこの問題に正解できる&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;209&#34;
		data-flex-basis=&#34;503px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;以前紹介したプロンプティングの&lt;a class=&#34;link&#34; href=&#34;https://qiita.com/kujirahand/items/aed18c8298bb9bd41934&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;few shotsなどを使えば改善する&lt;/a&gt;ことはよく知られていて、様々なプロンプティング解説サイトに書いてあります。とはいえ･･･計算問題はあまりChatGPTに任せない方が良いと考えた方が良いのではないでしょうか。&lt;/p&gt;
&lt;p&gt;最近見た話では、pythonプログラムとして目的の計算を実装させれば複雑な計算も可能だと聞きました。&lt;/p&gt;
&lt;iframe class=&#34;hatenablogcard&#34; style=&#34;width:100%;height:155px;&#34; src=&#34;https://hatenablog-parts.com/embed?url=https%3a%2f%2fnote.com%2fkaramanium%2fn%2fnde6c61c0afae&#34; width=&#34;300&#34; height=&#34;150&#34; frameborder=&#34;0&#34; scrolling=&#34;no&#34;&gt;&lt;/iframe&gt;

&lt;h2 id=&#34;個人情報は入力しちゃ絶対だめ&#34;&gt;個人情報は入力しちゃ絶対だめ！&lt;/h2&gt;
&lt;p&gt;これは非常に重要な注意事項なのですが、ChatGPTで行われた会話はOpenAIの学習データに転用される可能性があります。実際に&lt;a class=&#34;link&#34; href=&#34;https://www.businessinsider.jp/post-264782&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Amazonで入力された機密情報がChatGPTの出力から出てきてしまった&lt;/a&gt;こともあったらしく、要注意です。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://snitch0.github.io/p/ai-translate/warning.png&#34;
	width=&#34;499&#34;
	height=&#34;432&#34;
	srcset=&#34;https://snitch0.github.io/p/ai-translate/warning_hufda71a518df3491e9aa6a5223ef40c41_11603_480x0_resize_box_3.png 480w, https://snitch0.github.io/p/ai-translate/warning_hufda71a518df3491e9aa6a5223ef40c41_11603_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;ほとんどの人は忘れているかもしれないが、一応最初に注意がでます&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;115&#34;
		data-flex-basis=&#34;277px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;GPT-3.5、GPT-4のAPI版&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;であればデータを学習データに使われることはありません。また、つい&lt;a class=&#34;link&#34; href=&#34;https://www.itmedia.co.jp/news/articles/2304/26/news075.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;先日ヒストリーを記録できない代わりに学習データには使わないモードが実装されました&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://snitch0.github.io/p/ai-translate/setting.png&#34;
	width=&#34;663&#34;
	height=&#34;394&#34;
	srcset=&#34;https://snitch0.github.io/p/ai-translate/setting_huc9e133f5200afbfc134463075386a954_13974_480x0_resize_box_3.png 480w, https://snitch0.github.io/p/ai-translate/setting_huc9e133f5200afbfc134463075386a954_13974_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;左下のユーザーアイコンから設定を変えることが出来ます&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;168&#34;
		data-flex-basis=&#34;403px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;chatgptが得意なことは作文とプログラミング&#34;&gt;ChatGPTが得意なことは作文とプログラミング&lt;/h2&gt;
&lt;p&gt;計算が苦手なら何が得意か？個人的に私が安全に活用できると思っているのは作文とプログラミングです。&lt;/p&gt;
&lt;p&gt;たとえば、会社のお偉いさんに送るメールは失礼のないよう、数十分時間をかけて書いていた時期が私にもありました(しかもそれを上司が添削したりする)が、そういったことはChatGPTにやらせた方が良いです。また、倫理的にどうかは別として、読書感想文を作らせることも得意だと思います。いずれにせよ、何かしらのテーマで作文をさせる分にはChatGPTは余計なこともしないし、良い文章を作ってくれるはずです。論文を書くのにも役立つかもしれませんね。&lt;/p&gt;
&lt;p&gt;ChatGPTはプログラミングもかなり得意です。たとえば、ChatGPTでは「matplotlibを使って棒グラフを作りたい」とか「argparseを使ってコマンドライン引数をとるプログラムを作りたい」といったように、使い慣れないフレームワークに関してミニマムなコードをサクッと作成することができます。仮にエラーが出ても、エラー文ごとコピペ、修正を要求すれば正しいコードになって返ってきます。Step by Stepでコードを修正していけば、複雑な操作もちゃんとしたコードに落とし込んでくれるでしょう。&lt;/p&gt;
&lt;p&gt;ただ、たまにどうやっても動作しないようなコードを書いてくることもあります。pandasとpolarsを使い分けたりなど、新しめのフレームワークに関する細かい情報は当然知らないので、でたらめのコードでっち上げてくることがあります。プログラミングの場合は動作確認をしないわけがないので、すぐにファクトチェックされますけどね。&lt;/p&gt;
&lt;h2 id=&#34;gptは近い将来あらゆるアプリに組み込まれる&#34;&gt;GPTは近い将来あらゆるアプリに組み込まれる&lt;/h2&gt;
&lt;p&gt;前述のAPIが既に公開されているため、非常に多くのサービスがChatGPTを使ったサービスを展開しています。Powered by GPTで検索するとどんなサービスがあるか見つけられるでしょうが、サイトを読み込ませたらそのサイトについて教えてくれるチャットボットを作成するSiteGPTや、デザイン込みでレジュメを自動作成してくれるkickresumeなどがあります。&lt;/p&gt;
&lt;p&gt;APIに加えて、GPT-4を他のサービスとボタン一つで連携可能な&lt;a class=&#34;link&#34; href=&#34;https://openai.com/blog/chatgpt-plugins&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Plugin機能も公開予定であると発表されています&lt;/a&gt;。現状APIをうまく活用できるエンジニアだけが創意工夫で自由にサービスをローンチできる状況ですが、今後はAIを誰もが活用する時代が来るのでは無いかと考えられています。技術的な障壁はどんどん無くなっていくでしょう。&lt;/p&gt;
&lt;h2 id=&#34;生物系研究者はaiをどう活用すべきか&#34;&gt;生物系研究者はAIをどう活用すべきか&lt;/h2&gt;
&lt;p&gt;では最後に、生物系研究者がChatGPTを始めとするサービスを研究にどう活かしたら良いか、解説したいと思います。&lt;/p&gt;
&lt;h3 id=&#34;とにもかくにもgpt-35ではなくgpt-4を使いましょう&#34;&gt;とにもかくにもGPT-3.5ではなくGPT-4を使いましょう&lt;/h3&gt;
&lt;p&gt;GPT-3.5とGPT-4の差はかなり大きいです。通常GPT-4は月に$20も払わないといけないと使えないのですが、「それくらいなら安い」と思ったなら迷わず課金してください。$20で高校生くらいの頭脳を持ったAIが雇えるなら安いものだと私は考えています。&lt;/p&gt;
&lt;p&gt;別の方法としては、Edgeブラウザーに搭載されているBingを使う方法が挙げられます。EdgeはMicrosoftが開発しているブラウザで、Chromeみたいなものです。MicrosoftはGoogleが持つ検索エンジンとブラウザのシェアを奪うため、GPT-4をBingとしてEdgeに搭載しました。この中身がGPT-4で動いているため、課金しなくてもGPT-4を使うことが出来ます。&lt;/p&gt;
&lt;p&gt;EdgeのBingには以下のようなメリットがあります。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT-4を無料で使える&lt;/li&gt;
&lt;li&gt;Bingは検索エンジンとインテグレートされているので、出典が必ず記載される&lt;/li&gt;
&lt;li&gt;ChatGPTに存在する文字数制限が無い(が、全ての入力が反映されていない気もする)&lt;/li&gt;
&lt;li&gt;Webページ要約機能がある(Summarize current web pageなどとプロンプティングする)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一方デメリットはUIが若干見づらかったり、履歴が保存できないことです。また、性能的にChatGPTと同等なのかは割と謎です。あまり検証されていません。&lt;/p&gt;
&lt;h3 id=&#34;調べ物ならperplexityを使いましょう&#34;&gt;調べ物ならPerplexityを使いましょう&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.perplexity.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Perplexity.ai&lt;/a&gt;はChatGPTとも異なるセクターのサービスで、GPT-4やBingが発表される前から出典を添付してくれるチャットボットサービスとして公開されていました。GPT-4とどっちが賢いのかはあまりよく分かりませんが、調べ物をする上では極めて有用です。この数ヶ月私はめちゃめちゃ使っています。つい最近スマホアプリ版もリリースされました。&lt;/p&gt;
&lt;p&gt;また、この記事を書いているさなかにSerach-GPTなるサービスがOpenAIから発表されましたので、Perplexityに似たサービスがOpenAIからも出てくると思われます。&lt;/p&gt;
&lt;h3 id=&#34;chatgptはお役所仕事の時に使うのが良い&#34;&gt;ChatGPTはお役所仕事の時に使うのが良い&lt;/h3&gt;
&lt;p&gt;これは完全に私の個人的見解ですが、ChatGPTは手紙の書き出しや会社のお偉いさんへの形式張ったメール、科研費の申請など、表面上取り繕うことが重要なお役所的作文には適任だと思っています。シチュエーションや文面の内容、伝えてほしい細かいニュアンスなどを指示すれば、あなた好みで失礼の無い文面が簡単にできるはずです。&lt;/p&gt;
&lt;h3 id=&#34;ちょっとしたプログラミングには良い&#34;&gt;ちょっとしたプログラミングには良い&lt;/h3&gt;
&lt;p&gt;ChatGPTなどのAIサービスはプログラミングが得意ですが、まだまだ大きいサービスを一からプログラミングすることはできません。いずれ出来るようになるかもしれませんが、結局プログラマーやエンジニアの仕事がAIに奪われることはおそらく無いと思います。&lt;/p&gt;
&lt;p&gt;これからの時代は義務教育でプログラミングを学び、ちょっとしたプログラミングならすぐに実行できる人たちが社会に出てくるのだろうと思いますが、そういった方々はAIにミニマルなコードを書かせて業務効率化するような未来が最も現実的だと思います。少しだけPythonが書ける、C++が実行できる、といった環境構築だけしておけば、様々な場面でChatGPT製コードによる業務効率化が図れることでしょう。&lt;/p&gt;
&lt;h3 id=&#34;アイデアを想起する&#34;&gt;アイデアを想起する&lt;/h3&gt;
&lt;p&gt;GPT-4はただの確率的言語モデルには違いないのですが、このままいくと人間の思考力を凌駕すると可能性があると言われています。このまま学習データを大きくすれば確実に人間の思考力を超えるので、近い将来に起きることです。私はこれがある種神秘的な現象だと思っていて、「人間の神経細胞を模した計算機を用意して、虫食いの文章を覚えまくれば、内部の構造は理解できなくとも思考するロボットが完成する」ことを意味していると思います。つまり、哲学や善悪の判断、期待、愛情、、、人間の専売特許だと思われていた思考、魂とも呼称されるモノはTransformerモデルにより再現可能かもしれず、人類は脳科学の真理にたどり着いたのではないかと私は思うわけです。&lt;/p&gt;
&lt;p&gt;ではそれを前提として、倫理的にどうこれを扱うかは今まさに欧州各国などの有識者に任せるとして、我々はメリットデメリットを把握した上でうまく使いこなすことが重要なのではないでしょうか。ここまでに提案してきたChatGPTの使い方は表面的なものでしたが、Transformerモデルが人間に近い思考力を見せているとするならば、自分には思いつかなかったアイデアをAIに求めることもできるのではないでしょうか？&lt;/p&gt;
&lt;p&gt;現に、AIにより作成された絵画&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;ChatGPTがでまかせを述べてしまう現象のこと。既知の問題としてOpenAIも認識しています。&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;スクレイピング等の技術を使ってプログラムによりデータを自動収集する手法のこと。クロール禁止の規定を用意しているサイトも多いが、人間がウェブアクセスしたかのように見せる方法もあるので防ぎようが無い。&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;プログラムからWebサービスを実行するための仕組みです。ChatGPTのようなWebアプリとしてのUIがありませんが、自作のアプリなどにGPTを組み込むなどの応用が可能になります。APIは従量課金制ですが、随分安い利用料設定になっていることも一時話題になっていました。&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
        </item>
        
    </channel>
</rss>
